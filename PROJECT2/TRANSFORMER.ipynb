{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TRANSFORMER.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "27Jocpud5DeL"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "import tensorflow.keras.applications.inception_v3\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.nn import relu,softmax,tanh\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow.keras.preprocessing.image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pickle\n",
        "import nltk\n",
        "import cv2\n",
        "import string\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6XgiAwM5Jnv",
        "outputId": "8b7b5ed5-18f1-4dd5-f83a-7b2e93f998fc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuIml8rO5Ni-"
      },
      "source": [
        "#PATH TO ROOT FOLDER\n",
        "root_captioning=\"/content/gdrive/My Drive/projects/captions/\"\n",
        "image_path=\"/content/gdrive/My Drive/projects/captions/Flicker8k_Dataset\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9vGU5de5UVi"
      },
      "source": [
        "#LIST OF ALL THE IMAGES\n",
        "img_names1=glob.glob(os.path.join(image_path,'*.jpg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U47FFSpPfQj7"
      },
      "source": [
        "def img_slices(img):\n",
        "  img= tf.data.Dataset.from_tensor_slices(img)\n",
        "  return img\n",
        "\n",
        "def decode_image(img):\n",
        "  img=tf.image.decode_jpeg(img,channels=3)\n",
        "  img=tf.image.resize(img,(299,299))\n",
        "  return img\n",
        "\n",
        "def inception_preprocess(img):\n",
        "  img=tf.keras.applications.inception_v3.preprocess_input(img)\n",
        "  return img\n",
        "  \n",
        "def preprocess(image_dataset):\n",
        "  img=tf.io.read_file(image_dataset)\n",
        "  img=decode_image(img)\n",
        "  img=inception_preprocess(img)\n",
        "  return img,image_dataset\n",
        "\n",
        "def extract_features(img):\n",
        "  feat=inception_model(img)\n",
        "  return feat\n",
        "\n",
        "def features(image_path_list):\n",
        "  image_dataset=img_slices(image_path_list)\n",
        "  image_dataset=image_dataset.map(preprocess,num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(16)\n",
        "  for img,path in image_dataset:\n",
        "    batch_features=extract_features(img)\n",
        "    batch_features=tf.reshape(batch_features,(batch_features.shape[0],-1,batch_features.shape[3]))\n",
        "    for bf,p in zip(batch_features,path):\n",
        "      path_of_feature=p.numpy().decode('utf-8')\n",
        "      np.save(path_of_feature,bf.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHAYDW0efR0B"
      },
      "source": [
        "#features(img_names1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ddCzjQq5eIQ"
      },
      "source": [
        "#Make Dictionary Of All Items\n",
        "captions =open('/content/gdrive/My Drive/projects/captions/Flickr8k_text/Flickr8k.lemma.token1.txt').read().split(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2UEnK5D53si"
      },
      "source": [
        "#PreProcessed Dictionary\n",
        "pre_processed_captions=dict()\n",
        "for i in captions:\n",
        "  token=i.split()\n",
        "  if len(i)>=2:\n",
        "    id=token[0].split('#')[0]\n",
        "    img_path=os.path.join(image_path,id)\n",
        "    description=token[1:]\n",
        "    description=[i1.strip() for i1 in description]\n",
        "    cap=list()\n",
        "    cap.append(description)\n",
        "    \n",
        "\n",
        "    if img_path not in pre_processed_captions:\n",
        "      pre_processed_captions[img_path]=list()\n",
        "    pre_processed_captions[img_path].append([item for sublist in cap for item in sublist])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kv9IceRsQbdm"
      },
      "source": [
        "#CAPTIONS LIST\n",
        "captions_list=[]\n",
        "for i in captions:\n",
        "  token=i.split()\n",
        "  if len(i)>=2:\n",
        "    description=token[1:]\n",
        "    listToStr = ' '.join(map(str, description))\n",
        "    listToStr = listToStr.split('.')[0]\n",
        "    caption='<start> '+listToStr+' <end>'\n",
        "    captions_list.append(caption)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiecOMdNQg27"
      },
      "source": [
        "def tokenization(max_number_words):\n",
        "  token=Tokenizer(num_words=max_number_words,oov_token='<unk>',filters='!\"#$%&()*+.,-/:;=?@[\\]^_`{|}~ ')\n",
        "  return token\n",
        "\n",
        "def maxlength(sequences):\n",
        "  m11=max(len(s) for s in sequences)\n",
        "  return m11\n",
        "\n",
        "def padsequences(sequences,max_len):\n",
        "  pad11=pad_sequences(sequences,padding='post',maxlen=max_len)\n",
        "  return pad11"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFbD0u9BQmBY"
      },
      "source": [
        "#TOKENIZE THE TOP 5000 WORDS\n",
        "max_number_words=5000\n",
        "tokenizer=tokenization(max_number_words)\n",
        "tokenizer.fit_on_texts(captions_list)\n",
        "tokenizer.word_index['<pad>'] = 0\n",
        "tokenizer.index_word[0] = '<pad>'\n",
        "sequences=tokenizer.texts_to_sequences(captions_list)\n",
        "max_len=maxlength(sequences)\n",
        "padded_captions=pad_sequences(sequences,max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jc8Y3oL0QqSM"
      },
      "source": [
        "#GIVE THE IMG_IDS WHOLE IMAGE PATH\n",
        "img_names1=list()\n",
        "for i in captions:\n",
        "  token=i.split()\n",
        "  if len(i)>=2:\n",
        "    i1=i.split('#')[0]\n",
        "    img_path=os.path.join(image_path,i1)\n",
        "    img_names1.append(img_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRumUeVTQvTA"
      },
      "source": [
        "#DIVIDE THE DATASET INTO TRAIN AND TEST\n",
        "img_names_train, img_names_test, captions_train, captions_test = train_test_split(img_names1, padded_captions, test_size=0.25, random_state=123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgOtgsOe55DB"
      },
      "source": [
        "#DEFINE INCEPTION MODEL\n",
        "inceptionV3 = InceptionV3(include_top=False, weights='imagenet')\n",
        "inception_model = Model(inceptionV3.input, inceptionV3.output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDGrYywMIhHu"
      },
      "source": [
        "#GET POSITIONAL ANGLES\n",
        "def get_angles(pos, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "    return pos * angle_rates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47EBan1NIkfI"
      },
      "source": [
        "#DEFINE POSITIONAL ENCODING\n",
        "def positional_encoding(position, d_model):\n",
        "    angle_rads = get_angles(np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model)\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])  \n",
        "    pos_encoding = angle_rads[np.newaxis, ...] \n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyyHa8QxIm1Z"
      },
      "source": [
        "#CREATE PADDING MASK\n",
        "def create_padding_mask(seq):\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "    return seq[:, tf.newaxis, tf.newaxis, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdAI1cvqIo-Z"
      },
      "source": [
        "#CREATE LOOKAHEAD MASK\n",
        "def create_look_ahead_mask(size):\n",
        "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "    return mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vibi7cnbKa2L"
      },
      "source": [
        "# CREATE SCALED DOT PRODUCT ATTENTION\n",
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)  \n",
        "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
        "    output = tf.matmul(attention_weights, v)  \n",
        "    return output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVBLoIqoK2Ys"
      },
      "source": [
        "# CREATE MULTIHEAD ATTENTION\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "        assert d_model % self.num_heads == 0\n",
        "        self.depth = d_model // self.num_heads\n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "        \n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "    \n",
        "    def call(self, v, k, q, mask):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "        q = self.wq(q)\n",
        "        k = self.wk(k)\n",
        "        v = self.wv(v)\n",
        "        q = self.split_heads(q, batch_size)\n",
        "        k = self.split_heads(k, batch_size)\n",
        "        v = self.split_heads(v, batch_size)\n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "        concat_attention = tf.reshape(scaled_attention,(batch_size, -1, self.d_model))\n",
        "        output = self.dense(concat_attention)\n",
        "        return output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjwIBivpNkJA"
      },
      "source": [
        "# POINT WISE FEED FORWARD NEURAL NETWORK\n",
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "    return tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(dff, activation='relu'),\n",
        "        tf.keras.layers.Dense(d_model)\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VdB8yDiLWwy"
      },
      "source": [
        "# CREATE ENCODER LAYER\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    def call(self, x, training, mask):\n",
        "        attn_output, _ = self.mha(x, x, x, mask)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)\n",
        "        return out2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWBZ-ZYVNkLl"
      },
      "source": [
        "# CREATE DECODER LAYER\n",
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout3 = tf.keras.layers.Dropout(rate)   \n",
        "    \n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n",
        "        attn1 = self.dropout1(attn1, training=training)\n",
        "        out1 = self.layernorm1(attn1 + x)    \n",
        "        attn2, attn_weights_block2 = self.mha2(\n",
        "            enc_output, enc_output, out1, padding_mask)\n",
        "        attn2 = self.dropout2(attn2, training=training)\n",
        "        out2 = self.layernorm2(attn2 + out1)\n",
        "        ffn_output = self.ffn(out2)\n",
        "        ffn_output = self.dropout3(ffn_output, training=training)\n",
        "        out3 = self.layernorm3(ffn_output + out2)\n",
        "        return out3, attn_weights_block1, attn_weights_block2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiGmDeFaLt3W"
      },
      "source": [
        "# CREATE ENCODER MODULE\n",
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding,self.d_model)\n",
        "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]      \n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "        self.embedding2 = Dense(d_model)\n",
        "        \n",
        "    def call(self, x, training, mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        x = self.embedding2(x)\n",
        "        x = relu(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "        x = self.dropout(x, training=training)    \n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training, mask)  \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4WEBGQGNkOn"
      },
      "source": [
        "# CREATE DECODER MODULE\n",
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        attention_weights = {}\n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "        x = self.dropout(x, training=training)\n",
        "        for i in range(self.num_layers):\n",
        "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
        "            \n",
        "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "        return x, attention_weights\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d5_NHJgNkQx"
      },
      "source": [
        "#CREATE TRANSFORMER \n",
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n",
        "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)\n",
        "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "    \n",
        "    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
        "        enc_output = self.encoder(inp, training, enc_padding_mask)\n",
        "        dec_output, attention_weights = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)    \n",
        "        final_output = self.final_layer(dec_output)\n",
        "        return final_output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMw8a74ClofW"
      },
      "source": [
        "#SET HYPER PARAMETERS\n",
        "batch_size = 128\n",
        "num_layers = 4\n",
        "d_model = 128\n",
        "buffer_size = 1000\n",
        "dff = 256\n",
        "num_heads = 4\n",
        "target_vocab_size = 5001\n",
        "input_vocab_size = target_vocab_size\n",
        "dropout_rate = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "004fqlW8L1hJ"
      },
      "source": [
        "#DEFINE TRANSFORMER\n",
        "transformer = Transformer(num_layers, d_model, num_heads, dff, \n",
        "                          input_vocab_size, target_vocab_size, \n",
        "                          pe_input=input_vocab_size, \n",
        "                          pe_target=target_vocab_size, \n",
        "                          rate=dropout_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXPC8hQUR6xq"
      },
      "source": [
        "#CREATE MASK\n",
        "def create_masks(inp, tar):\n",
        "    enc_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "    dec_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "    dec_target_padding_mask = create_padding_mask(tar)\n",
        "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "    return enc_padding_mask, combined_mask, dec_padding_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cp31ORC3QNth"
      },
      "source": [
        "#CREATE MAP FUNCTION\n",
        "def map_func(img_name, cap):\n",
        "    img_tensor = np.load(img_name.decode('utf-8')+'.npy')\n",
        "    return img_tensor, cap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x74Ehwd-NkTi"
      },
      "source": [
        "#CREATE DATASET\n",
        "dataset = tf.data.Dataset.from_tensor_slices((img_names_train, captions_train))\n",
        "\n",
        "dataset = dataset.map(lambda item1, item2: tf.numpy_function(\n",
        "    map_func, [item1, item2], [tf.float32, tf.int32]),\n",
        "    num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "dataset = dataset.shuffle(buffer_size).batch(batch_size)\n",
        "dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOlbR7BCQ38X"
      },
      "source": [
        "#CUSTOM HYPER PARAMETER TUNER\n",
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=5):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEO-y86JRPj5"
      },
      "source": [
        "#DEFINE LEARNING RATE\n",
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
        "                                     epsilon=1e-9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhpYanS8NpX4"
      },
      "source": [
        "#CALCULATE LOSS AND ACCURACY\n",
        "loss_object = SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "# custom-loss function\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
        "\n",
        "def accuracy_function(real, pred):\n",
        "    accuracies = tf.equal(tf.cast(real,tf.float32), tf.cast(tf.argmax(pred, axis=2),tf.float32))\n",
        "\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    accuracies = tf.math.logical_and(mask, accuracies)\n",
        "\n",
        "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
        "    mask = tf.cast(mask, dtype=tf.float32)\n",
        "    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arYAodldOyln",
        "outputId": "1d146b6d-ac07-44a0-8e0f-ed1747fc55a8"
      },
      "source": [
        "#DEFINE CHECK POINT\n",
        "chkpt_path = '/content/gdrive/My Drive/transformer/train'\n",
        "chkpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n",
        "chkpt_manager = tf.train.CheckpointManager(chkpt, chkpt_path, max_to_keep=1)\n",
        "if chkpt_manager.latest_checkpoint:\n",
        "    print(\"Found a checkpoint\")\n",
        "    chkpt.restore(chkpt_manager.latest_checkpoint)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found a checkpoint\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5JH8K1yNr-J"
      },
      "source": [
        "#CREATE TRAIN STEP FOR LOSS FUNCTION\n",
        "@tf.function\n",
        "def train_step(inp, tar):\n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "    _, combined_mask, _ = create_masks(inp, tar_inp)  \n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions, _ = transformer(inp, tar_inp, True, None, combined_mask, None)\n",
        "        loss = loss_function(tar_real, predictions)\n",
        "        gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
        "        optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eySTeQ-2Oeir"
      },
      "source": [
        "#CREATE TRAIN STEP FOR ACCURACY FUNCTION\n",
        "@tf.function\n",
        "def train_step1(inp, tar):\n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "    _, combined_mask, _ = create_masks(inp, tar_inp)  \n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions, _ = transformer(inp, tar_inp, True, None, combined_mask, None)\n",
        "        accuracy = accuracy_function(tar_real, predictions)\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdc_DiYCUnnh",
        "outputId": "95a4ad60-29c1-4b97-f98e-fc3a1685596f"
      },
      "source": [
        "#GENERATOR TO RUN THE DATA\n",
        "EPOCHS = 199\n",
        "start_epoch=0\n",
        "train_losses=[]\n",
        "for epoch in range(start_epoch, EPOCHS+1):\n",
        "    start = time.time()\n",
        "    total_loss = 0\n",
        "\n",
        "    for (batch, (img_tensor, target)) in enumerate(dataset):\n",
        "        batch_loss = train_step(img_tensor, target)\n",
        "        batch_acc = train_step1(img_tensor, target)\n",
        "        total_loss += batch_loss\n",
        "\n",
        "        if batch % 50 == 0:\n",
        "            print ('Epoch {} Batch {} Loss {:.4f}'.format(\n",
        "              epoch + 1, batch, batch_loss.numpy() / int(target.shape[1])))\n",
        "            \n",
        "            print ('Epoch {} Batch {} Accuracy {:.4f}'.format(\n",
        "              epoch + 1, batch, batch_acc.numpy() / int(target.shape[1])))\n",
        "    # storing the epoch end loss value to plot later\n",
        "    \n",
        "    train_losses.append(total_loss/(len(img_names_train) // batch_size))\n",
        "    if epoch % 5 == 0:\n",
        "      pickle.dump(train_losses, open(\"/content/gdrive/My Drive/transformer/losses.p\", \"wb\"))\n",
        "      chkpt_manager.save()\n",
        "\n",
        "    print ('Epoch {} Loss {:.6f}'.format(epoch + 1,total_loss/(len(img_names_train) // batch_size)))\n",
        "    print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 0.1288\n",
            "Epoch 1 Batch 0 Accuracy 0.0035\n",
            "Epoch 1 Batch 50 Loss 0.1287\n",
            "Epoch 1 Batch 50 Accuracy 0.0035\n",
            "Epoch 1 Batch 100 Loss 0.1298\n",
            "Epoch 1 Batch 100 Accuracy 0.0035\n",
            "Epoch 1 Batch 150 Loss 0.1278\n",
            "Epoch 1 Batch 150 Accuracy 0.0036\n",
            "Epoch 1 Batch 200 Loss 0.1290\n",
            "Epoch 1 Batch 200 Accuracy 0.0032\n",
            "Epoch 1 Loss 5.014317\n",
            "Time taken for 1 epoch 84.32505011558533 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 0.1301\n",
            "Epoch 2 Batch 0 Accuracy 0.0034\n",
            "Epoch 2 Batch 50 Loss 0.1283\n",
            "Epoch 2 Batch 50 Accuracy 0.0033\n",
            "Epoch 2 Batch 100 Loss 0.1257\n",
            "Epoch 2 Batch 100 Accuracy 0.0037\n",
            "Epoch 2 Batch 150 Loss 0.1291\n",
            "Epoch 2 Batch 150 Accuracy 0.0034\n",
            "Epoch 2 Batch 200 Loss 0.1271\n",
            "Epoch 2 Batch 200 Accuracy 0.0035\n",
            "Epoch 2 Loss 5.015590\n",
            "Time taken for 1 epoch 66.1200020313263 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.1300\n",
            "Epoch 3 Batch 0 Accuracy 0.0033\n",
            "Epoch 3 Batch 50 Loss 0.1275\n",
            "Epoch 3 Batch 50 Accuracy 0.0034\n",
            "Epoch 3 Batch 100 Loss 0.1279\n",
            "Epoch 3 Batch 100 Accuracy 0.0035\n",
            "Epoch 3 Batch 150 Loss 0.1281\n",
            "Epoch 3 Batch 150 Accuracy 0.0036\n",
            "Epoch 3 Batch 200 Loss 0.1268\n",
            "Epoch 3 Batch 200 Accuracy 0.0033\n",
            "Epoch 3 Loss 5.011489\n",
            "Time taken for 1 epoch 65.97854018211365 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.1269\n",
            "Epoch 4 Batch 0 Accuracy 0.0034\n",
            "Epoch 4 Batch 50 Loss 0.1278\n",
            "Epoch 4 Batch 50 Accuracy 0.0036\n",
            "Epoch 4 Batch 100 Loss 0.1273\n",
            "Epoch 4 Batch 100 Accuracy 0.0039\n",
            "Epoch 4 Batch 150 Loss 0.1298\n",
            "Epoch 4 Batch 150 Accuracy 0.0032\n",
            "Epoch 4 Batch 200 Loss 0.1267\n",
            "Epoch 4 Batch 200 Accuracy 0.0034\n",
            "Epoch 4 Loss 5.011271\n",
            "Time taken for 1 epoch 66.34832167625427 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.1290\n",
            "Epoch 5 Batch 0 Accuracy 0.0033\n",
            "Epoch 5 Batch 50 Loss 0.1258\n",
            "Epoch 5 Batch 50 Accuracy 0.0036\n",
            "Epoch 5 Batch 100 Loss 0.1278\n",
            "Epoch 5 Batch 100 Accuracy 0.0035\n",
            "Epoch 5 Batch 150 Loss 0.1257\n",
            "Epoch 5 Batch 150 Accuracy 0.0035\n",
            "Epoch 5 Batch 200 Loss 0.1269\n",
            "Epoch 5 Batch 200 Accuracy 0.0037\n",
            "Epoch 5 Loss 5.012054\n",
            "Time taken for 1 epoch 66.2538526058197 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.1284\n",
            "Epoch 6 Batch 0 Accuracy 0.0034\n",
            "Epoch 6 Batch 50 Loss 0.1270\n",
            "Epoch 6 Batch 50 Accuracy 0.0036\n",
            "Epoch 6 Batch 100 Loss 0.1285\n",
            "Epoch 6 Batch 100 Accuracy 0.0035\n",
            "Epoch 6 Batch 150 Loss 0.1282\n",
            "Epoch 6 Batch 150 Accuracy 0.0035\n",
            "Epoch 6 Batch 200 Loss 0.1264\n",
            "Epoch 6 Batch 200 Accuracy 0.0034\n",
            "Epoch 6 Loss 5.009873\n",
            "Time taken for 1 epoch 67.44181561470032 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.1273\n",
            "Epoch 7 Batch 0 Accuracy 0.0034\n",
            "Epoch 7 Batch 50 Loss 0.1266\n",
            "Epoch 7 Batch 50 Accuracy 0.0035\n",
            "Epoch 7 Batch 100 Loss 0.1281\n",
            "Epoch 7 Batch 100 Accuracy 0.0034\n",
            "Epoch 7 Batch 150 Loss 0.1282\n",
            "Epoch 7 Batch 150 Accuracy 0.0032\n",
            "Epoch 7 Batch 200 Loss 0.1273\n",
            "Epoch 7 Batch 200 Accuracy 0.0031\n",
            "Epoch 7 Loss 5.008343\n",
            "Time taken for 1 epoch 66.58963990211487 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.1271\n",
            "Epoch 8 Batch 0 Accuracy 0.0036\n",
            "Epoch 8 Batch 50 Loss 0.1276\n",
            "Epoch 8 Batch 50 Accuracy 0.0034\n",
            "Epoch 8 Batch 100 Loss 0.1301\n",
            "Epoch 8 Batch 100 Accuracy 0.0032\n",
            "Epoch 8 Batch 150 Loss 0.1265\n",
            "Epoch 8 Batch 150 Accuracy 0.0036\n",
            "Epoch 8 Batch 200 Loss 0.1258\n",
            "Epoch 8 Batch 200 Accuracy 0.0036\n",
            "Epoch 8 Loss 5.009419\n",
            "Time taken for 1 epoch 66.91584300994873 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.1284\n",
            "Epoch 9 Batch 0 Accuracy 0.0033\n",
            "Epoch 9 Batch 50 Loss 0.1293\n",
            "Epoch 9 Batch 50 Accuracy 0.0033\n",
            "Epoch 9 Batch 100 Loss 0.1285\n",
            "Epoch 9 Batch 100 Accuracy 0.0033\n",
            "Epoch 9 Batch 150 Loss 0.1280\n",
            "Epoch 9 Batch 150 Accuracy 0.0036\n",
            "Epoch 9 Batch 200 Loss 0.1274\n",
            "Epoch 9 Batch 200 Accuracy 0.0034\n",
            "Epoch 9 Loss 5.009481\n",
            "Time taken for 1 epoch 67.32706809043884 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.1290\n",
            "Epoch 10 Batch 0 Accuracy 0.0031\n",
            "Epoch 10 Batch 50 Loss 0.1293\n",
            "Epoch 10 Batch 50 Accuracy 0.0033\n",
            "Epoch 10 Batch 100 Loss 0.1264\n",
            "Epoch 10 Batch 100 Accuracy 0.0037\n",
            "Epoch 10 Batch 150 Loss 0.1274\n",
            "Epoch 10 Batch 150 Accuracy 0.0034\n",
            "Epoch 10 Batch 200 Loss 0.1272\n",
            "Epoch 10 Batch 200 Accuracy 0.0036\n",
            "Epoch 10 Loss 5.007201\n",
            "Time taken for 1 epoch 67.45907926559448 sec\n",
            "\n",
            "Epoch 11 Batch 0 Loss 0.1278\n",
            "Epoch 11 Batch 0 Accuracy 0.0035\n",
            "Epoch 11 Batch 50 Loss 0.1288\n",
            "Epoch 11 Batch 50 Accuracy 0.0034\n",
            "Epoch 11 Batch 100 Loss 0.1275\n",
            "Epoch 11 Batch 100 Accuracy 0.0037\n",
            "Epoch 11 Batch 150 Loss 0.1261\n",
            "Epoch 11 Batch 150 Accuracy 0.0035\n",
            "Epoch 11 Batch 200 Loss 0.1284\n",
            "Epoch 11 Batch 200 Accuracy 0.0036\n",
            "Epoch 11 Loss 5.008927\n",
            "Time taken for 1 epoch 68.55743622779846 sec\n",
            "\n",
            "Epoch 12 Batch 0 Loss 0.1259\n",
            "Epoch 12 Batch 0 Accuracy 0.0033\n",
            "Epoch 12 Batch 50 Loss 0.1267\n",
            "Epoch 12 Batch 50 Accuracy 0.0034\n",
            "Epoch 12 Batch 100 Loss 0.1265\n",
            "Epoch 12 Batch 100 Accuracy 0.0036\n",
            "Epoch 12 Batch 150 Loss 0.1282\n",
            "Epoch 12 Batch 150 Accuracy 0.0032\n",
            "Epoch 12 Batch 200 Loss 0.1281\n",
            "Epoch 12 Batch 200 Accuracy 0.0033\n",
            "Epoch 12 Loss 5.009262\n",
            "Time taken for 1 epoch 68.10929608345032 sec\n",
            "\n",
            "Epoch 13 Batch 0 Loss 0.1280\n",
            "Epoch 13 Batch 0 Accuracy 0.0033\n",
            "Epoch 13 Batch 50 Loss 0.1271\n",
            "Epoch 13 Batch 50 Accuracy 0.0035\n",
            "Epoch 13 Batch 100 Loss 0.1286\n",
            "Epoch 13 Batch 100 Accuracy 0.0033\n",
            "Epoch 13 Batch 150 Loss 0.1305\n",
            "Epoch 13 Batch 150 Accuracy 0.0033\n",
            "Epoch 13 Batch 200 Loss 0.1273\n",
            "Epoch 13 Batch 200 Accuracy 0.0035\n",
            "Epoch 13 Loss 5.009491\n",
            "Time taken for 1 epoch 68.17799806594849 sec\n",
            "\n",
            "Epoch 14 Batch 0 Loss 0.1284\n",
            "Epoch 14 Batch 0 Accuracy 0.0036\n",
            "Epoch 14 Batch 50 Loss 0.1267\n",
            "Epoch 14 Batch 50 Accuracy 0.0034\n",
            "Epoch 14 Batch 100 Loss 0.1297\n",
            "Epoch 14 Batch 100 Accuracy 0.0033\n",
            "Epoch 14 Batch 150 Loss 0.1270\n",
            "Epoch 14 Batch 150 Accuracy 0.0035\n",
            "Epoch 14 Batch 200 Loss 0.1272\n",
            "Epoch 14 Batch 200 Accuracy 0.0032\n",
            "Epoch 14 Loss 5.008687\n",
            "Time taken for 1 epoch 67.95760822296143 sec\n",
            "\n",
            "Epoch 15 Batch 0 Loss 0.1278\n",
            "Epoch 15 Batch 0 Accuracy 0.0036\n",
            "Epoch 15 Batch 50 Loss 0.1270\n",
            "Epoch 15 Batch 50 Accuracy 0.0034\n",
            "Epoch 15 Batch 100 Loss 0.1280\n",
            "Epoch 15 Batch 100 Accuracy 0.0035\n",
            "Epoch 15 Batch 150 Loss 0.1259\n",
            "Epoch 15 Batch 150 Accuracy 0.0036\n",
            "Epoch 15 Batch 200 Loss 0.1266\n",
            "Epoch 15 Batch 200 Accuracy 0.0034\n",
            "Epoch 15 Loss 5.006937\n",
            "Time taken for 1 epoch 68.66507625579834 sec\n",
            "\n",
            "Epoch 16 Batch 0 Loss 0.1277\n",
            "Epoch 16 Batch 0 Accuracy 0.0036\n",
            "Epoch 16 Batch 50 Loss 0.1261\n",
            "Epoch 16 Batch 50 Accuracy 0.0038\n",
            "Epoch 16 Batch 100 Loss 0.1283\n",
            "Epoch 16 Batch 100 Accuracy 0.0034\n",
            "Epoch 16 Batch 150 Loss 0.1272\n",
            "Epoch 16 Batch 150 Accuracy 0.0037\n",
            "Epoch 16 Batch 200 Loss 0.1267\n",
            "Epoch 16 Batch 200 Accuracy 0.0033\n",
            "Epoch 16 Loss 5.009217\n",
            "Time taken for 1 epoch 68.44566082954407 sec\n",
            "\n",
            "Epoch 17 Batch 0 Loss 0.1275\n",
            "Epoch 17 Batch 0 Accuracy 0.0036\n",
            "Epoch 17 Batch 50 Loss 0.1275\n",
            "Epoch 17 Batch 50 Accuracy 0.0035\n",
            "Epoch 17 Batch 100 Loss 0.1259\n",
            "Epoch 17 Batch 100 Accuracy 0.0035\n",
            "Epoch 17 Batch 150 Loss 0.1278\n",
            "Epoch 17 Batch 150 Accuracy 0.0035\n",
            "Epoch 17 Batch 200 Loss 0.1258\n",
            "Epoch 17 Batch 200 Accuracy 0.0037\n",
            "Epoch 17 Loss 5.006792\n",
            "Time taken for 1 epoch 68.31319689750671 sec\n",
            "\n",
            "Epoch 18 Batch 0 Loss 0.1273\n",
            "Epoch 18 Batch 0 Accuracy 0.0036\n",
            "Epoch 18 Batch 50 Loss 0.1261\n",
            "Epoch 18 Batch 50 Accuracy 0.0036\n",
            "Epoch 18 Batch 100 Loss 0.1267\n",
            "Epoch 18 Batch 100 Accuracy 0.0039\n",
            "Epoch 18 Batch 150 Loss 0.1288\n",
            "Epoch 18 Batch 150 Accuracy 0.0031\n",
            "Epoch 18 Batch 200 Loss 0.1290\n",
            "Epoch 18 Batch 200 Accuracy 0.0035\n",
            "Epoch 18 Loss 5.008648\n",
            "Time taken for 1 epoch 67.60127997398376 sec\n",
            "\n",
            "Epoch 19 Batch 0 Loss 0.1297\n",
            "Epoch 19 Batch 0 Accuracy 0.0034\n",
            "Epoch 19 Batch 50 Loss 0.1288\n",
            "Epoch 19 Batch 50 Accuracy 0.0035\n",
            "Epoch 19 Batch 100 Loss 0.1259\n",
            "Epoch 19 Batch 100 Accuracy 0.0036\n",
            "Epoch 19 Batch 150 Loss 0.1280\n",
            "Epoch 19 Batch 150 Accuracy 0.0034\n",
            "Epoch 19 Batch 200 Loss 0.1295\n",
            "Epoch 19 Batch 200 Accuracy 0.0032\n",
            "Epoch 19 Loss 5.005553\n",
            "Time taken for 1 epoch 66.60072159767151 sec\n",
            "\n",
            "Epoch 20 Batch 0 Loss 0.1280\n",
            "Epoch 20 Batch 0 Accuracy 0.0035\n",
            "Epoch 20 Batch 50 Loss 0.1285\n",
            "Epoch 20 Batch 50 Accuracy 0.0032\n",
            "Epoch 20 Batch 100 Loss 0.1280\n",
            "Epoch 20 Batch 100 Accuracy 0.0034\n",
            "Epoch 20 Batch 150 Loss 0.1298\n",
            "Epoch 20 Batch 150 Accuracy 0.0034\n",
            "Epoch 20 Batch 200 Loss 0.1270\n",
            "Epoch 20 Batch 200 Accuracy 0.0035\n",
            "Epoch 20 Loss 5.006029\n",
            "Time taken for 1 epoch 66.2187705039978 sec\n",
            "\n",
            "Epoch 21 Batch 0 Loss 0.1274\n",
            "Epoch 21 Batch 0 Accuracy 0.0035\n",
            "Epoch 21 Batch 50 Loss 0.1253\n",
            "Epoch 21 Batch 50 Accuracy 0.0035\n",
            "Epoch 21 Batch 100 Loss 0.1268\n",
            "Epoch 21 Batch 100 Accuracy 0.0036\n",
            "Epoch 21 Batch 150 Loss 0.1286\n",
            "Epoch 21 Batch 150 Accuracy 0.0033\n",
            "Epoch 21 Batch 200 Loss 0.1286\n",
            "Epoch 21 Batch 200 Accuracy 0.0035\n",
            "Epoch 21 Loss 5.007640\n",
            "Time taken for 1 epoch 65.40378189086914 sec\n",
            "\n",
            "Epoch 22 Batch 0 Loss 0.1278\n",
            "Epoch 22 Batch 0 Accuracy 0.0034\n",
            "Epoch 22 Batch 50 Loss 0.1281\n",
            "Epoch 22 Batch 50 Accuracy 0.0032\n",
            "Epoch 22 Batch 100 Loss 0.1289\n",
            "Epoch 22 Batch 100 Accuracy 0.0031\n",
            "Epoch 22 Batch 150 Loss 0.1271\n",
            "Epoch 22 Batch 150 Accuracy 0.0036\n",
            "Epoch 22 Batch 200 Loss 0.1289\n",
            "Epoch 22 Batch 200 Accuracy 0.0034\n",
            "Epoch 22 Loss 5.006977\n",
            "Time taken for 1 epoch 65.15446138381958 sec\n",
            "\n",
            "Epoch 23 Batch 0 Loss 0.1278\n",
            "Epoch 23 Batch 0 Accuracy 0.0034\n",
            "Epoch 23 Batch 50 Loss 0.1265\n",
            "Epoch 23 Batch 50 Accuracy 0.0038\n",
            "Epoch 23 Batch 100 Loss 0.1290\n",
            "Epoch 23 Batch 100 Accuracy 0.0034\n",
            "Epoch 23 Batch 150 Loss 0.1268\n",
            "Epoch 23 Batch 150 Accuracy 0.0032\n",
            "Epoch 23 Batch 200 Loss 0.1273\n",
            "Epoch 23 Batch 200 Accuracy 0.0032\n",
            "Epoch 23 Loss 5.005287\n",
            "Time taken for 1 epoch 64.67545437812805 sec\n",
            "\n",
            "Epoch 24 Batch 0 Loss 0.1268\n",
            "Epoch 24 Batch 0 Accuracy 0.0035\n",
            "Epoch 24 Batch 50 Loss 0.1286\n",
            "Epoch 24 Batch 50 Accuracy 0.0036\n",
            "Epoch 24 Batch 100 Loss 0.1268\n",
            "Epoch 24 Batch 100 Accuracy 0.0037\n",
            "Epoch 24 Batch 150 Loss 0.1291\n",
            "Epoch 24 Batch 150 Accuracy 0.0035\n",
            "Epoch 24 Batch 200 Loss 0.1260\n",
            "Epoch 24 Batch 200 Accuracy 0.0035\n",
            "Epoch 24 Loss 5.006507\n",
            "Time taken for 1 epoch 64.47540307044983 sec\n",
            "\n",
            "Epoch 25 Batch 0 Loss 0.1270\n",
            "Epoch 25 Batch 0 Accuracy 0.0035\n",
            "Epoch 25 Batch 50 Loss 0.1253\n",
            "Epoch 25 Batch 50 Accuracy 0.0037\n",
            "Epoch 25 Batch 100 Loss 0.1262\n",
            "Epoch 25 Batch 100 Accuracy 0.0035\n",
            "Epoch 25 Batch 150 Loss 0.1260\n",
            "Epoch 25 Batch 150 Accuracy 0.0035\n",
            "Epoch 25 Batch 200 Loss 0.1269\n",
            "Epoch 25 Batch 200 Accuracy 0.0035\n",
            "Epoch 25 Loss 5.007613\n",
            "Time taken for 1 epoch 64.91995096206665 sec\n",
            "\n",
            "Epoch 26 Batch 0 Loss 0.1292\n",
            "Epoch 26 Batch 0 Accuracy 0.0032\n",
            "Epoch 26 Batch 50 Loss 0.1286\n",
            "Epoch 26 Batch 50 Accuracy 0.0034\n",
            "Epoch 26 Batch 100 Loss 0.1286\n",
            "Epoch 26 Batch 100 Accuracy 0.0036\n",
            "Epoch 26 Batch 150 Loss 0.1269\n",
            "Epoch 26 Batch 150 Accuracy 0.0035\n",
            "Epoch 26 Batch 200 Loss 0.1268\n",
            "Epoch 26 Batch 200 Accuracy 0.0035\n",
            "Epoch 26 Loss 5.007436\n",
            "Time taken for 1 epoch 64.69300627708435 sec\n",
            "\n",
            "Epoch 27 Batch 0 Loss 0.1304\n",
            "Epoch 27 Batch 0 Accuracy 0.0030\n",
            "Epoch 27 Batch 50 Loss 0.1283\n",
            "Epoch 27 Batch 50 Accuracy 0.0034\n",
            "Epoch 27 Batch 100 Loss 0.1271\n",
            "Epoch 27 Batch 100 Accuracy 0.0037\n",
            "Epoch 27 Batch 150 Loss 0.1266\n",
            "Epoch 27 Batch 150 Accuracy 0.0035\n",
            "Epoch 27 Batch 200 Loss 0.1274\n",
            "Epoch 27 Batch 200 Accuracy 0.0034\n",
            "Epoch 27 Loss 5.007355\n",
            "Time taken for 1 epoch 64.78154492378235 sec\n",
            "\n",
            "Epoch 28 Batch 0 Loss 0.1292\n",
            "Epoch 28 Batch 0 Accuracy 0.0034\n",
            "Epoch 28 Batch 50 Loss 0.1297\n",
            "Epoch 28 Batch 50 Accuracy 0.0034\n",
            "Epoch 28 Batch 100 Loss 0.1271\n",
            "Epoch 28 Batch 100 Accuracy 0.0035\n",
            "Epoch 28 Batch 150 Loss 0.1267\n",
            "Epoch 28 Batch 150 Accuracy 0.0036\n",
            "Epoch 28 Batch 200 Loss 0.1267\n",
            "Epoch 28 Batch 200 Accuracy 0.0035\n",
            "Epoch 28 Loss 5.007300\n",
            "Time taken for 1 epoch 64.32153725624084 sec\n",
            "\n",
            "Epoch 29 Batch 0 Loss 0.1302\n",
            "Epoch 29 Batch 0 Accuracy 0.0033\n",
            "Epoch 29 Batch 50 Loss 0.1287\n",
            "Epoch 29 Batch 50 Accuracy 0.0036\n",
            "Epoch 29 Batch 100 Loss 0.1292\n",
            "Epoch 29 Batch 100 Accuracy 0.0034\n",
            "Epoch 29 Batch 150 Loss 0.1294\n",
            "Epoch 29 Batch 150 Accuracy 0.0036\n",
            "Epoch 29 Batch 200 Loss 0.1287\n",
            "Epoch 29 Batch 200 Accuracy 0.0032\n",
            "Epoch 29 Loss 5.005624\n",
            "Time taken for 1 epoch 64.73608160018921 sec\n",
            "\n",
            "Epoch 30 Batch 0 Loss 0.1301\n",
            "Epoch 30 Batch 0 Accuracy 0.0034\n",
            "Epoch 30 Batch 50 Loss 0.1270\n",
            "Epoch 30 Batch 50 Accuracy 0.0033\n",
            "Epoch 30 Batch 100 Loss 0.1255\n",
            "Epoch 30 Batch 100 Accuracy 0.0036\n",
            "Epoch 30 Batch 150 Loss 0.1273\n",
            "Epoch 30 Batch 150 Accuracy 0.0035\n",
            "Epoch 30 Batch 200 Loss 0.1297\n",
            "Epoch 30 Batch 200 Accuracy 0.0034\n",
            "Epoch 30 Loss 5.007202\n",
            "Time taken for 1 epoch 64.44761300086975 sec\n",
            "\n",
            "Epoch 31 Batch 0 Loss 0.1271\n",
            "Epoch 31 Batch 0 Accuracy 0.0033\n",
            "Epoch 31 Batch 50 Loss 0.1284\n",
            "Epoch 31 Batch 50 Accuracy 0.0035\n",
            "Epoch 31 Batch 100 Loss 0.1274\n",
            "Epoch 31 Batch 100 Accuracy 0.0036\n",
            "Epoch 31 Batch 150 Loss 0.1235\n",
            "Epoch 31 Batch 150 Accuracy 0.0037\n",
            "Epoch 31 Batch 200 Loss 0.1261\n",
            "Epoch 31 Batch 200 Accuracy 0.0037\n",
            "Epoch 31 Loss 5.006993\n",
            "Time taken for 1 epoch 64.47705173492432 sec\n",
            "\n",
            "Epoch 32 Batch 0 Loss 0.1277\n",
            "Epoch 32 Batch 0 Accuracy 0.0035\n",
            "Epoch 32 Batch 50 Loss 0.1283\n",
            "Epoch 32 Batch 50 Accuracy 0.0033\n",
            "Epoch 32 Batch 100 Loss 0.1284\n",
            "Epoch 32 Batch 100 Accuracy 0.0034\n",
            "Epoch 32 Batch 150 Loss 0.1281\n",
            "Epoch 32 Batch 150 Accuracy 0.0035\n",
            "Epoch 32 Batch 200 Loss 0.1283\n",
            "Epoch 32 Batch 200 Accuracy 0.0035\n",
            "Epoch 32 Loss 5.005180\n",
            "Time taken for 1 epoch 64.58097076416016 sec\n",
            "\n",
            "Epoch 33 Batch 0 Loss 0.1286\n",
            "Epoch 33 Batch 0 Accuracy 0.0036\n",
            "Epoch 33 Batch 50 Loss 0.1281\n",
            "Epoch 33 Batch 50 Accuracy 0.0033\n",
            "Epoch 33 Batch 100 Loss 0.1268\n",
            "Epoch 33 Batch 100 Accuracy 0.0036\n",
            "Epoch 33 Batch 150 Loss 0.1287\n",
            "Epoch 33 Batch 150 Accuracy 0.0036\n",
            "Epoch 33 Batch 200 Loss 0.1289\n",
            "Epoch 33 Batch 200 Accuracy 0.0033\n",
            "Epoch 33 Loss 5.005232\n",
            "Time taken for 1 epoch 64.47070741653442 sec\n",
            "\n",
            "Epoch 34 Batch 0 Loss 0.1280\n",
            "Epoch 34 Batch 0 Accuracy 0.0034\n",
            "Epoch 34 Batch 50 Loss 0.1277\n",
            "Epoch 34 Batch 50 Accuracy 0.0035\n",
            "Epoch 34 Batch 100 Loss 0.1267\n",
            "Epoch 34 Batch 100 Accuracy 0.0037\n",
            "Epoch 34 Batch 150 Loss 0.1278\n",
            "Epoch 34 Batch 150 Accuracy 0.0035\n",
            "Epoch 34 Batch 200 Loss 0.1267\n",
            "Epoch 34 Batch 200 Accuracy 0.0034\n",
            "Epoch 34 Loss 5.005073\n",
            "Time taken for 1 epoch 65.23039674758911 sec\n",
            "\n",
            "Epoch 35 Batch 0 Loss 0.1295\n",
            "Epoch 35 Batch 0 Accuracy 0.0035\n",
            "Epoch 35 Batch 50 Loss 0.1268\n",
            "Epoch 35 Batch 50 Accuracy 0.0037\n",
            "Epoch 35 Batch 100 Loss 0.1257\n",
            "Epoch 35 Batch 100 Accuracy 0.0037\n",
            "Epoch 35 Batch 150 Loss 0.1265\n",
            "Epoch 35 Batch 150 Accuracy 0.0034\n",
            "Epoch 35 Batch 200 Loss 0.1276\n",
            "Epoch 35 Batch 200 Accuracy 0.0033\n",
            "Epoch 35 Loss 5.006475\n",
            "Time taken for 1 epoch 64.80138158798218 sec\n",
            "\n",
            "Epoch 36 Batch 0 Loss 0.1270\n",
            "Epoch 36 Batch 0 Accuracy 0.0037\n",
            "Epoch 36 Batch 50 Loss 0.1293\n",
            "Epoch 36 Batch 50 Accuracy 0.0034\n",
            "Epoch 36 Batch 100 Loss 0.1271\n",
            "Epoch 36 Batch 100 Accuracy 0.0032\n",
            "Epoch 36 Batch 150 Loss 0.1263\n",
            "Epoch 36 Batch 150 Accuracy 0.0038\n",
            "Epoch 36 Batch 200 Loss 0.1273\n",
            "Epoch 36 Batch 200 Accuracy 0.0033\n",
            "Epoch 36 Loss 5.001667\n",
            "Time taken for 1 epoch 65.00537490844727 sec\n",
            "\n",
            "Epoch 37 Batch 0 Loss 0.1275\n",
            "Epoch 37 Batch 0 Accuracy 0.0034\n",
            "Epoch 37 Batch 50 Loss 0.1285\n",
            "Epoch 37 Batch 50 Accuracy 0.0036\n",
            "Epoch 37 Batch 100 Loss 0.1283\n",
            "Epoch 37 Batch 100 Accuracy 0.0035\n",
            "Epoch 37 Batch 150 Loss 0.1282\n",
            "Epoch 37 Batch 150 Accuracy 0.0038\n",
            "Epoch 37 Batch 200 Loss 0.1284\n",
            "Epoch 37 Batch 200 Accuracy 0.0033\n",
            "Epoch 37 Loss 5.006453\n",
            "Time taken for 1 epoch 65.80388832092285 sec\n",
            "\n",
            "Epoch 38 Batch 0 Loss 0.1269\n",
            "Epoch 38 Batch 0 Accuracy 0.0039\n",
            "Epoch 38 Batch 50 Loss 0.1296\n",
            "Epoch 38 Batch 50 Accuracy 0.0033\n",
            "Epoch 38 Batch 100 Loss 0.1273\n",
            "Epoch 38 Batch 100 Accuracy 0.0035\n",
            "Epoch 38 Batch 150 Loss 0.1268\n",
            "Epoch 38 Batch 150 Accuracy 0.0036\n",
            "Epoch 38 Batch 200 Loss 0.1252\n",
            "Epoch 38 Batch 200 Accuracy 0.0034\n",
            "Epoch 38 Loss 5.004323\n",
            "Time taken for 1 epoch 65.20530772209167 sec\n",
            "\n",
            "Epoch 39 Batch 0 Loss 0.1279\n",
            "Epoch 39 Batch 0 Accuracy 0.0034\n",
            "Epoch 39 Batch 50 Loss 0.1288\n",
            "Epoch 39 Batch 50 Accuracy 0.0034\n",
            "Epoch 39 Batch 100 Loss 0.1267\n",
            "Epoch 39 Batch 100 Accuracy 0.0037\n",
            "Epoch 39 Batch 150 Loss 0.1270\n",
            "Epoch 39 Batch 150 Accuracy 0.0034\n",
            "Epoch 39 Batch 200 Loss 0.1260\n",
            "Epoch 39 Batch 200 Accuracy 0.0035\n",
            "Epoch 39 Loss 5.007120\n",
            "Time taken for 1 epoch 66.16375207901001 sec\n",
            "\n",
            "Epoch 40 Batch 0 Loss 0.1287\n",
            "Epoch 40 Batch 0 Accuracy 0.0036\n",
            "Epoch 40 Batch 50 Loss 0.1273\n",
            "Epoch 40 Batch 50 Accuracy 0.0035\n",
            "Epoch 40 Batch 100 Loss 0.1287\n",
            "Epoch 40 Batch 100 Accuracy 0.0036\n",
            "Epoch 40 Batch 150 Loss 0.1295\n",
            "Epoch 40 Batch 150 Accuracy 0.0034\n",
            "Epoch 40 Batch 200 Loss 0.1282\n",
            "Epoch 40 Batch 200 Accuracy 0.0036\n",
            "Epoch 40 Loss 5.006227\n",
            "Time taken for 1 epoch 65.42943167686462 sec\n",
            "\n",
            "Epoch 41 Batch 0 Loss 0.1274\n",
            "Epoch 41 Batch 0 Accuracy 0.0033\n",
            "Epoch 41 Batch 50 Loss 0.1255\n",
            "Epoch 41 Batch 50 Accuracy 0.0039\n",
            "Epoch 41 Batch 100 Loss 0.1290\n",
            "Epoch 41 Batch 100 Accuracy 0.0033\n",
            "Epoch 41 Batch 150 Loss 0.1275\n",
            "Epoch 41 Batch 150 Accuracy 0.0035\n",
            "Epoch 41 Batch 200 Loss 0.1257\n",
            "Epoch 41 Batch 200 Accuracy 0.0037\n",
            "Epoch 41 Loss 5.005009\n",
            "Time taken for 1 epoch 66.00970363616943 sec\n",
            "\n",
            "Epoch 42 Batch 0 Loss 0.1288\n",
            "Epoch 42 Batch 0 Accuracy 0.0035\n",
            "Epoch 42 Batch 50 Loss 0.1279\n",
            "Epoch 42 Batch 50 Accuracy 0.0032\n",
            "Epoch 42 Batch 100 Loss 0.1255\n",
            "Epoch 42 Batch 100 Accuracy 0.0038\n",
            "Epoch 42 Batch 150 Loss 0.1281\n",
            "Epoch 42 Batch 150 Accuracy 0.0034\n",
            "Epoch 42 Batch 200 Loss 0.1293\n",
            "Epoch 42 Batch 200 Accuracy 0.0031\n",
            "Epoch 42 Loss 5.004624\n",
            "Time taken for 1 epoch 66.15679049491882 sec\n",
            "\n",
            "Epoch 43 Batch 0 Loss 0.1282\n",
            "Epoch 43 Batch 0 Accuracy 0.0035\n",
            "Epoch 43 Batch 50 Loss 0.1296\n",
            "Epoch 43 Batch 50 Accuracy 0.0034\n",
            "Epoch 43 Batch 100 Loss 0.1261\n",
            "Epoch 43 Batch 100 Accuracy 0.0035\n",
            "Epoch 43 Batch 150 Loss 0.1277\n",
            "Epoch 43 Batch 150 Accuracy 0.0034\n",
            "Epoch 43 Batch 200 Loss 0.1282\n",
            "Epoch 43 Batch 200 Accuracy 0.0035\n",
            "Epoch 43 Loss 5.003953\n",
            "Time taken for 1 epoch 66.17885255813599 sec\n",
            "\n",
            "Epoch 44 Batch 0 Loss 0.1271\n",
            "Epoch 44 Batch 0 Accuracy 0.0036\n",
            "Epoch 44 Batch 50 Loss 0.1283\n",
            "Epoch 44 Batch 50 Accuracy 0.0033\n",
            "Epoch 44 Batch 100 Loss 0.1272\n",
            "Epoch 44 Batch 100 Accuracy 0.0035\n",
            "Epoch 44 Batch 150 Loss 0.1261\n",
            "Epoch 44 Batch 150 Accuracy 0.0036\n",
            "Epoch 44 Batch 200 Loss 0.1284\n",
            "Epoch 44 Batch 200 Accuracy 0.0034\n",
            "Epoch 44 Loss 5.005225\n",
            "Time taken for 1 epoch 66.91519451141357 sec\n",
            "\n",
            "Epoch 45 Batch 0 Loss 0.1290\n",
            "Epoch 45 Batch 0 Accuracy 0.0036\n",
            "Epoch 45 Batch 50 Loss 0.1285\n",
            "Epoch 45 Batch 50 Accuracy 0.0035\n",
            "Epoch 45 Batch 100 Loss 0.1277\n",
            "Epoch 45 Batch 100 Accuracy 0.0035\n",
            "Epoch 45 Batch 150 Loss 0.1275\n",
            "Epoch 45 Batch 150 Accuracy 0.0035\n",
            "Epoch 45 Batch 200 Loss 0.1281\n",
            "Epoch 45 Batch 200 Accuracy 0.0034\n",
            "Epoch 45 Loss 5.004485\n",
            "Time taken for 1 epoch 66.47886919975281 sec\n",
            "\n",
            "Epoch 46 Batch 0 Loss 0.1276\n",
            "Epoch 46 Batch 0 Accuracy 0.0035\n",
            "Epoch 46 Batch 50 Loss 0.1261\n",
            "Epoch 46 Batch 50 Accuracy 0.0036\n",
            "Epoch 46 Batch 100 Loss 0.1285\n",
            "Epoch 46 Batch 100 Accuracy 0.0034\n",
            "Epoch 46 Batch 150 Loss 0.1277\n",
            "Epoch 46 Batch 150 Accuracy 0.0037\n",
            "Epoch 46 Batch 200 Loss 0.1254\n",
            "Epoch 46 Batch 200 Accuracy 0.0036\n",
            "Epoch 46 Loss 5.007028\n",
            "Time taken for 1 epoch 66.94409990310669 sec\n",
            "\n",
            "Epoch 47 Batch 0 Loss 0.1273\n",
            "Epoch 47 Batch 0 Accuracy 0.0033\n",
            "Epoch 47 Batch 50 Loss 0.1295\n",
            "Epoch 47 Batch 50 Accuracy 0.0033\n",
            "Epoch 47 Batch 100 Loss 0.1261\n",
            "Epoch 47 Batch 100 Accuracy 0.0037\n",
            "Epoch 47 Batch 150 Loss 0.1280\n",
            "Epoch 47 Batch 150 Accuracy 0.0037\n",
            "Epoch 47 Batch 200 Loss 0.1275\n",
            "Epoch 47 Batch 200 Accuracy 0.0035\n",
            "Epoch 47 Loss 5.005365\n",
            "Time taken for 1 epoch 66.73474788665771 sec\n",
            "\n",
            "Epoch 48 Batch 0 Loss 0.1276\n",
            "Epoch 48 Batch 0 Accuracy 0.0036\n",
            "Epoch 48 Batch 50 Loss 0.1263\n",
            "Epoch 48 Batch 50 Accuracy 0.0035\n",
            "Epoch 48 Batch 100 Loss 0.1282\n",
            "Epoch 48 Batch 100 Accuracy 0.0036\n",
            "Epoch 48 Batch 150 Loss 0.1288\n",
            "Epoch 48 Batch 150 Accuracy 0.0033\n",
            "Epoch 48 Batch 200 Loss 0.1275\n",
            "Epoch 48 Batch 200 Accuracy 0.0034\n",
            "Epoch 48 Loss 5.004418\n",
            "Time taken for 1 epoch 67.45362257957458 sec\n",
            "\n",
            "Epoch 49 Batch 0 Loss 0.1268\n",
            "Epoch 49 Batch 0 Accuracy 0.0034\n",
            "Epoch 49 Batch 50 Loss 0.1278\n",
            "Epoch 49 Batch 50 Accuracy 0.0036\n",
            "Epoch 49 Batch 100 Loss 0.1250\n",
            "Epoch 49 Batch 100 Accuracy 0.0037\n",
            "Epoch 49 Batch 150 Loss 0.1265\n",
            "Epoch 49 Batch 150 Accuracy 0.0037\n",
            "Epoch 49 Batch 200 Loss 0.1265\n",
            "Epoch 49 Batch 200 Accuracy 0.0035\n",
            "Epoch 49 Loss 5.004536\n",
            "Time taken for 1 epoch 66.0946569442749 sec\n",
            "\n",
            "Epoch 50 Batch 0 Loss 0.1281\n",
            "Epoch 50 Batch 0 Accuracy 0.0035\n",
            "Epoch 50 Batch 50 Loss 0.1292\n",
            "Epoch 50 Batch 50 Accuracy 0.0032\n",
            "Epoch 50 Batch 100 Loss 0.1288\n",
            "Epoch 50 Batch 100 Accuracy 0.0036\n",
            "Epoch 50 Batch 150 Loss 0.1279\n",
            "Epoch 50 Batch 150 Accuracy 0.0034\n",
            "Epoch 50 Batch 200 Loss 0.1282\n",
            "Epoch 50 Batch 200 Accuracy 0.0034\n",
            "Epoch 50 Loss 5.007185\n",
            "Time taken for 1 epoch 65.5641565322876 sec\n",
            "\n",
            "Epoch 51 Batch 0 Loss 0.1276\n",
            "Epoch 51 Batch 0 Accuracy 0.0036\n",
            "Epoch 51 Batch 50 Loss 0.1283\n",
            "Epoch 51 Batch 50 Accuracy 0.0034\n",
            "Epoch 51 Batch 100 Loss 0.1272\n",
            "Epoch 51 Batch 100 Accuracy 0.0036\n",
            "Epoch 51 Batch 150 Loss 0.1278\n",
            "Epoch 51 Batch 150 Accuracy 0.0035\n",
            "Epoch 51 Batch 200 Loss 0.1272\n",
            "Epoch 51 Batch 200 Accuracy 0.0034\n",
            "Epoch 51 Loss 5.005841\n",
            "Time taken for 1 epoch 65.72265958786011 sec\n",
            "\n",
            "Epoch 52 Batch 0 Loss 0.1296\n",
            "Epoch 52 Batch 0 Accuracy 0.0035\n",
            "Epoch 52 Batch 50 Loss 0.1267\n",
            "Epoch 52 Batch 50 Accuracy 0.0034\n",
            "Epoch 52 Batch 100 Loss 0.1245\n",
            "Epoch 52 Batch 100 Accuracy 0.0035\n",
            "Epoch 52 Batch 150 Loss 0.1272\n",
            "Epoch 52 Batch 150 Accuracy 0.0034\n",
            "Epoch 52 Batch 200 Loss 0.1275\n",
            "Epoch 52 Batch 200 Accuracy 0.0033\n",
            "Epoch 52 Loss 5.009175\n",
            "Time taken for 1 epoch 65.90352439880371 sec\n",
            "\n",
            "Epoch 53 Batch 0 Loss 0.1296\n",
            "Epoch 53 Batch 0 Accuracy 0.0037\n",
            "Epoch 53 Batch 50 Loss 0.1245\n",
            "Epoch 53 Batch 50 Accuracy 0.0035\n",
            "Epoch 53 Batch 100 Loss 0.1274\n",
            "Epoch 53 Batch 100 Accuracy 0.0035\n",
            "Epoch 53 Batch 150 Loss 0.1271\n",
            "Epoch 53 Batch 150 Accuracy 0.0036\n",
            "Epoch 53 Batch 200 Loss 0.1289\n",
            "Epoch 53 Batch 200 Accuracy 0.0034\n",
            "Epoch 53 Loss 5.006023\n",
            "Time taken for 1 epoch 66.2484564781189 sec\n",
            "\n",
            "Epoch 54 Batch 0 Loss 0.1276\n",
            "Epoch 54 Batch 0 Accuracy 0.0035\n",
            "Epoch 54 Batch 50 Loss 0.1298\n",
            "Epoch 54 Batch 50 Accuracy 0.0034\n",
            "Epoch 54 Batch 100 Loss 0.1256\n",
            "Epoch 54 Batch 100 Accuracy 0.0035\n",
            "Epoch 54 Batch 150 Loss 0.1273\n",
            "Epoch 54 Batch 150 Accuracy 0.0034\n",
            "Epoch 54 Batch 200 Loss 0.1286\n",
            "Epoch 54 Batch 200 Accuracy 0.0034\n",
            "Epoch 54 Loss 4.993873\n",
            "Time taken for 1 epoch 66.12191987037659 sec\n",
            "\n",
            "Epoch 55 Batch 0 Loss 0.1300\n",
            "Epoch 55 Batch 0 Accuracy 0.0034\n",
            "Epoch 55 Batch 50 Loss 0.1256\n",
            "Epoch 55 Batch 50 Accuracy 0.0038\n",
            "Epoch 55 Batch 100 Loss 0.1262\n",
            "Epoch 55 Batch 100 Accuracy 0.0035\n",
            "Epoch 55 Batch 150 Loss 0.1286\n",
            "Epoch 55 Batch 150 Accuracy 0.0035\n",
            "Epoch 55 Batch 200 Loss 0.1259\n",
            "Epoch 55 Batch 200 Accuracy 0.0035\n",
            "Epoch 55 Loss 5.006005\n",
            "Time taken for 1 epoch 66.51263523101807 sec\n",
            "\n",
            "Epoch 56 Batch 0 Loss 0.1297\n",
            "Epoch 56 Batch 0 Accuracy 0.0036\n",
            "Epoch 56 Batch 50 Loss 0.1264\n",
            "Epoch 56 Batch 50 Accuracy 0.0036\n",
            "Epoch 56 Batch 100 Loss 0.1293\n",
            "Epoch 56 Batch 100 Accuracy 0.0035\n",
            "Epoch 56 Batch 150 Loss 0.1294\n",
            "Epoch 56 Batch 150 Accuracy 0.0034\n",
            "Epoch 56 Batch 200 Loss 0.1265\n",
            "Epoch 56 Batch 200 Accuracy 0.0038\n",
            "Epoch 56 Loss 5.008235\n",
            "Time taken for 1 epoch 66.98969960212708 sec\n",
            "\n",
            "Epoch 57 Batch 0 Loss 0.1253\n",
            "Epoch 57 Batch 0 Accuracy 0.0038\n",
            "Epoch 57 Batch 50 Loss 0.1270\n",
            "Epoch 57 Batch 50 Accuracy 0.0037\n",
            "Epoch 57 Batch 100 Loss 0.1268\n",
            "Epoch 57 Batch 100 Accuracy 0.0034\n",
            "Epoch 57 Batch 150 Loss 0.1276\n",
            "Epoch 57 Batch 150 Accuracy 0.0036\n",
            "Epoch 57 Batch 200 Loss 0.1270\n",
            "Epoch 57 Batch 200 Accuracy 0.0033\n",
            "Epoch 57 Loss 5.006503\n",
            "Time taken for 1 epoch 67.54640555381775 sec\n",
            "\n",
            "Epoch 58 Batch 0 Loss 0.1287\n",
            "Epoch 58 Batch 0 Accuracy 0.0032\n",
            "Epoch 58 Batch 50 Loss 0.1299\n",
            "Epoch 58 Batch 50 Accuracy 0.0033\n",
            "Epoch 58 Batch 100 Loss 0.1285\n",
            "Epoch 58 Batch 100 Accuracy 0.0034\n",
            "Epoch 58 Batch 150 Loss 0.1301\n",
            "Epoch 58 Batch 150 Accuracy 0.0032\n",
            "Epoch 58 Batch 200 Loss 0.1262\n",
            "Epoch 58 Batch 200 Accuracy 0.0034\n",
            "Epoch 58 Loss 5.005908\n",
            "Time taken for 1 epoch 66.98174357414246 sec\n",
            "\n",
            "Epoch 59 Batch 0 Loss 0.1287\n",
            "Epoch 59 Batch 0 Accuracy 0.0035\n",
            "Epoch 59 Batch 50 Loss 0.1269\n",
            "Epoch 59 Batch 50 Accuracy 0.0033\n",
            "Epoch 59 Batch 100 Loss 0.1269\n",
            "Epoch 59 Batch 100 Accuracy 0.0037\n",
            "Epoch 59 Batch 150 Loss 0.1272\n",
            "Epoch 59 Batch 150 Accuracy 0.0037\n",
            "Epoch 59 Batch 200 Loss 0.1277\n",
            "Epoch 59 Batch 200 Accuracy 0.0034\n",
            "Epoch 59 Loss 5.003987\n",
            "Time taken for 1 epoch 66.79257464408875 sec\n",
            "\n",
            "Epoch 60 Batch 0 Loss 0.1292\n",
            "Epoch 60 Batch 0 Accuracy 0.0034\n",
            "Epoch 60 Batch 50 Loss 0.1275\n",
            "Epoch 60 Batch 50 Accuracy 0.0038\n",
            "Epoch 60 Batch 100 Loss 0.1279\n",
            "Epoch 60 Batch 100 Accuracy 0.0037\n",
            "Epoch 60 Batch 150 Loss 0.1274\n",
            "Epoch 60 Batch 150 Accuracy 0.0035\n",
            "Epoch 60 Batch 200 Loss 0.1252\n",
            "Epoch 60 Batch 200 Accuracy 0.0034\n",
            "Epoch 60 Loss 5.004579\n",
            "Time taken for 1 epoch 67.27601289749146 sec\n",
            "\n",
            "Epoch 61 Batch 0 Loss 0.1259\n",
            "Epoch 61 Batch 0 Accuracy 0.0035\n",
            "Epoch 61 Batch 50 Loss 0.1263\n",
            "Epoch 61 Batch 50 Accuracy 0.0036\n",
            "Epoch 61 Batch 100 Loss 0.1281\n",
            "Epoch 61 Batch 100 Accuracy 0.0036\n",
            "Epoch 61 Batch 150 Loss 0.1283\n",
            "Epoch 61 Batch 150 Accuracy 0.0034\n",
            "Epoch 61 Batch 200 Loss 0.1274\n",
            "Epoch 61 Batch 200 Accuracy 0.0037\n",
            "Epoch 61 Loss 5.005405\n",
            "Time taken for 1 epoch 67.6267442703247 sec\n",
            "\n",
            "Epoch 62 Batch 0 Loss 0.1288\n",
            "Epoch 62 Batch 0 Accuracy 0.0034\n",
            "Epoch 62 Batch 50 Loss 0.1261\n",
            "Epoch 62 Batch 50 Accuracy 0.0037\n",
            "Epoch 62 Batch 100 Loss 0.1271\n",
            "Epoch 62 Batch 100 Accuracy 0.0036\n",
            "Epoch 62 Batch 150 Loss 0.1270\n",
            "Epoch 62 Batch 150 Accuracy 0.0033\n",
            "Epoch 62 Batch 200 Loss 0.1278\n",
            "Epoch 62 Batch 200 Accuracy 0.0035\n",
            "Epoch 62 Loss 5.005610\n",
            "Time taken for 1 epoch 68.47375154495239 sec\n",
            "\n",
            "Epoch 63 Batch 0 Loss 0.1279\n",
            "Epoch 63 Batch 0 Accuracy 0.0034\n",
            "Epoch 63 Batch 50 Loss 0.1267\n",
            "Epoch 63 Batch 50 Accuracy 0.0034\n",
            "Epoch 63 Batch 100 Loss 0.1279\n",
            "Epoch 63 Batch 100 Accuracy 0.0035\n",
            "Epoch 63 Batch 150 Loss 0.1273\n",
            "Epoch 63 Batch 150 Accuracy 0.0034\n",
            "Epoch 63 Batch 200 Loss 0.1283\n",
            "Epoch 63 Batch 200 Accuracy 0.0034\n",
            "Epoch 63 Loss 5.004322\n",
            "Time taken for 1 epoch 67.73245811462402 sec\n",
            "\n",
            "Epoch 64 Batch 0 Loss 0.1265\n",
            "Epoch 64 Batch 0 Accuracy 0.0034\n",
            "Epoch 64 Batch 50 Loss 0.1284\n",
            "Epoch 64 Batch 50 Accuracy 0.0036\n",
            "Epoch 64 Batch 100 Loss 0.1281\n",
            "Epoch 64 Batch 100 Accuracy 0.0036\n",
            "Epoch 64 Batch 150 Loss 0.1264\n",
            "Epoch 64 Batch 150 Accuracy 0.0033\n",
            "Epoch 64 Batch 200 Loss 0.1260\n",
            "Epoch 64 Batch 200 Accuracy 0.0036\n",
            "Epoch 64 Loss 5.004439\n",
            "Time taken for 1 epoch 66.09817457199097 sec\n",
            "\n",
            "Epoch 65 Batch 0 Loss 0.1274\n",
            "Epoch 65 Batch 0 Accuracy 0.0035\n",
            "Epoch 65 Batch 50 Loss 0.1282\n",
            "Epoch 65 Batch 50 Accuracy 0.0035\n",
            "Epoch 65 Batch 100 Loss 0.1279\n",
            "Epoch 65 Batch 100 Accuracy 0.0034\n",
            "Epoch 65 Batch 150 Loss 0.1253\n",
            "Epoch 65 Batch 150 Accuracy 0.0038\n",
            "Epoch 65 Batch 200 Loss 0.1279\n",
            "Epoch 65 Batch 200 Accuracy 0.0035\n",
            "Epoch 65 Loss 5.004792\n",
            "Time taken for 1 epoch 65.64201664924622 sec\n",
            "\n",
            "Epoch 66 Batch 0 Loss 0.1294\n",
            "Epoch 66 Batch 0 Accuracy 0.0035\n",
            "Epoch 66 Batch 50 Loss 0.1288\n",
            "Epoch 66 Batch 50 Accuracy 0.0033\n",
            "Epoch 66 Batch 100 Loss 0.1277\n",
            "Epoch 66 Batch 100 Accuracy 0.0035\n",
            "Epoch 66 Batch 150 Loss 0.1285\n",
            "Epoch 66 Batch 150 Accuracy 0.0033\n",
            "Epoch 66 Batch 200 Loss 0.1306\n",
            "Epoch 66 Batch 200 Accuracy 0.0031\n",
            "Epoch 66 Loss 5.004263\n",
            "Time taken for 1 epoch 66.11918091773987 sec\n",
            "\n",
            "Epoch 67 Batch 0 Loss 0.1311\n",
            "Epoch 67 Batch 0 Accuracy 0.0033\n",
            "Epoch 67 Batch 50 Loss 0.1253\n",
            "Epoch 67 Batch 50 Accuracy 0.0036\n",
            "Epoch 67 Batch 100 Loss 0.1285\n",
            "Epoch 67 Batch 100 Accuracy 0.0035\n",
            "Epoch 67 Batch 150 Loss 0.1278\n",
            "Epoch 67 Batch 150 Accuracy 0.0033\n",
            "Epoch 67 Batch 200 Loss 0.1255\n",
            "Epoch 67 Batch 200 Accuracy 0.0034\n",
            "Epoch 67 Loss 5.003994\n",
            "Time taken for 1 epoch 66.4872510433197 sec\n",
            "\n",
            "Epoch 68 Batch 0 Loss 0.1277\n",
            "Epoch 68 Batch 0 Accuracy 0.0036\n",
            "Epoch 68 Batch 50 Loss 0.1292\n",
            "Epoch 68 Batch 50 Accuracy 0.0035\n",
            "Epoch 68 Batch 100 Loss 0.1266\n",
            "Epoch 68 Batch 100 Accuracy 0.0034\n",
            "Epoch 68 Batch 150 Loss 0.1266\n",
            "Epoch 68 Batch 150 Accuracy 0.0034\n",
            "Epoch 68 Batch 200 Loss 0.1280\n",
            "Epoch 68 Batch 200 Accuracy 0.0034\n",
            "Epoch 68 Loss 5.004938\n",
            "Time taken for 1 epoch 65.6958634853363 sec\n",
            "\n",
            "Epoch 69 Batch 0 Loss 0.1267\n",
            "Epoch 69 Batch 0 Accuracy 0.0034\n",
            "Epoch 69 Batch 50 Loss 0.1277\n",
            "Epoch 69 Batch 50 Accuracy 0.0039\n",
            "Epoch 69 Batch 100 Loss 0.1255\n",
            "Epoch 69 Batch 100 Accuracy 0.0037\n",
            "Epoch 69 Batch 150 Loss 0.1284\n",
            "Epoch 69 Batch 150 Accuracy 0.0033\n",
            "Epoch 69 Batch 200 Loss 0.1285\n",
            "Epoch 69 Batch 200 Accuracy 0.0034\n",
            "Epoch 69 Loss 5.003929\n",
            "Time taken for 1 epoch 65.90492391586304 sec\n",
            "\n",
            "Epoch 70 Batch 0 Loss 0.1270\n",
            "Epoch 70 Batch 0 Accuracy 0.0033\n",
            "Epoch 70 Batch 50 Loss 0.1268\n",
            "Epoch 70 Batch 50 Accuracy 0.0037\n",
            "Epoch 70 Batch 100 Loss 0.1265\n",
            "Epoch 70 Batch 100 Accuracy 0.0035\n",
            "Epoch 70 Batch 150 Loss 0.1270\n",
            "Epoch 70 Batch 150 Accuracy 0.0036\n",
            "Epoch 70 Batch 200 Loss 0.1272\n",
            "Epoch 70 Batch 200 Accuracy 0.0032\n",
            "Epoch 70 Loss 5.005044\n",
            "Time taken for 1 epoch 65.93099570274353 sec\n",
            "\n",
            "Epoch 71 Batch 0 Loss 0.1288\n",
            "Epoch 71 Batch 0 Accuracy 0.0035\n",
            "Epoch 71 Batch 50 Loss 0.1269\n",
            "Epoch 71 Batch 50 Accuracy 0.0036\n",
            "Epoch 71 Batch 100 Loss 0.1275\n",
            "Epoch 71 Batch 100 Accuracy 0.0037\n",
            "Epoch 71 Batch 150 Loss 0.1270\n",
            "Epoch 71 Batch 150 Accuracy 0.0035\n",
            "Epoch 71 Batch 200 Loss 0.1288\n",
            "Epoch 71 Batch 200 Accuracy 0.0035\n",
            "Epoch 71 Loss 5.006307\n",
            "Time taken for 1 epoch 66.5029034614563 sec\n",
            "\n",
            "Epoch 72 Batch 0 Loss 0.1282\n",
            "Epoch 72 Batch 0 Accuracy 0.0036\n",
            "Epoch 72 Batch 50 Loss 0.1291\n",
            "Epoch 72 Batch 50 Accuracy 0.0034\n",
            "Epoch 72 Batch 100 Loss 0.1260\n",
            "Epoch 72 Batch 100 Accuracy 0.0034\n",
            "Epoch 72 Batch 150 Loss 0.1268\n",
            "Epoch 72 Batch 150 Accuracy 0.0034\n",
            "Epoch 72 Batch 200 Loss 0.1273\n",
            "Epoch 72 Batch 200 Accuracy 0.0032\n",
            "Epoch 72 Loss 5.005972\n",
            "Time taken for 1 epoch 67.13839721679688 sec\n",
            "\n",
            "Epoch 73 Batch 0 Loss 0.1274\n",
            "Epoch 73 Batch 0 Accuracy 0.0035\n",
            "Epoch 73 Batch 50 Loss 0.1274\n",
            "Epoch 73 Batch 50 Accuracy 0.0037\n",
            "Epoch 73 Batch 100 Loss 0.1279\n",
            "Epoch 73 Batch 100 Accuracy 0.0032\n",
            "Epoch 73 Batch 150 Loss 0.1282\n",
            "Epoch 73 Batch 150 Accuracy 0.0034\n",
            "Epoch 73 Batch 200 Loss 0.1271\n",
            "Epoch 73 Batch 200 Accuracy 0.0035\n",
            "Epoch 73 Loss 5.004703\n",
            "Time taken for 1 epoch 66.52719473838806 sec\n",
            "\n",
            "Epoch 74 Batch 0 Loss 0.1290\n",
            "Epoch 74 Batch 0 Accuracy 0.0034\n",
            "Epoch 74 Batch 50 Loss 0.1297\n",
            "Epoch 74 Batch 50 Accuracy 0.0035\n",
            "Epoch 74 Batch 100 Loss 0.1273\n",
            "Epoch 74 Batch 100 Accuracy 0.0038\n",
            "Epoch 74 Batch 150 Loss 0.1267\n",
            "Epoch 74 Batch 150 Accuracy 0.0036\n",
            "Epoch 74 Batch 200 Loss 0.1267\n",
            "Epoch 74 Batch 200 Accuracy 0.0033\n",
            "Epoch 74 Loss 5.003398\n",
            "Time taken for 1 epoch 65.98737597465515 sec\n",
            "\n",
            "Epoch 75 Batch 0 Loss 0.1295\n",
            "Epoch 75 Batch 0 Accuracy 0.0032\n",
            "Epoch 75 Batch 50 Loss 0.1269\n",
            "Epoch 75 Batch 50 Accuracy 0.0036\n",
            "Epoch 75 Batch 100 Loss 0.1246\n",
            "Epoch 75 Batch 100 Accuracy 0.0040\n",
            "Epoch 75 Batch 150 Loss 0.1288\n",
            "Epoch 75 Batch 150 Accuracy 0.0035\n",
            "Epoch 75 Batch 200 Loss 0.1286\n",
            "Epoch 75 Batch 200 Accuracy 0.0033\n",
            "Epoch 75 Loss 5.003860\n",
            "Time taken for 1 epoch 65.34411835670471 sec\n",
            "\n",
            "Epoch 76 Batch 0 Loss 0.1257\n",
            "Epoch 76 Batch 0 Accuracy 0.0035\n",
            "Epoch 76 Batch 50 Loss 0.1272\n",
            "Epoch 76 Batch 50 Accuracy 0.0036\n",
            "Epoch 76 Batch 100 Loss 0.1257\n",
            "Epoch 76 Batch 100 Accuracy 0.0036\n",
            "Epoch 76 Batch 150 Loss 0.1294\n",
            "Epoch 76 Batch 150 Accuracy 0.0032\n",
            "Epoch 76 Batch 200 Loss 0.1259\n",
            "Epoch 76 Batch 200 Accuracy 0.0035\n",
            "Epoch 76 Loss 5.006038\n",
            "Time taken for 1 epoch 65.9271719455719 sec\n",
            "\n",
            "Epoch 77 Batch 0 Loss 0.1296\n",
            "Epoch 77 Batch 0 Accuracy 0.0033\n",
            "Epoch 77 Batch 50 Loss 0.1286\n",
            "Epoch 77 Batch 50 Accuracy 0.0034\n",
            "Epoch 77 Batch 100 Loss 0.1281\n",
            "Epoch 77 Batch 100 Accuracy 0.0040\n",
            "Epoch 77 Batch 150 Loss 0.1273\n",
            "Epoch 77 Batch 150 Accuracy 0.0036\n",
            "Epoch 77 Batch 200 Loss 0.1262\n",
            "Epoch 77 Batch 200 Accuracy 0.0034\n",
            "Epoch 77 Loss 5.004331\n",
            "Time taken for 1 epoch 65.26356530189514 sec\n",
            "\n",
            "Epoch 78 Batch 0 Loss 0.1258\n",
            "Epoch 78 Batch 0 Accuracy 0.0036\n",
            "Epoch 78 Batch 50 Loss 0.1294\n",
            "Epoch 78 Batch 50 Accuracy 0.0037\n",
            "Epoch 78 Batch 100 Loss 0.1276\n",
            "Epoch 78 Batch 100 Accuracy 0.0036\n",
            "Epoch 78 Batch 150 Loss 0.1274\n",
            "Epoch 78 Batch 150 Accuracy 0.0036\n",
            "Epoch 78 Batch 200 Loss 0.1241\n",
            "Epoch 78 Batch 200 Accuracy 0.0036\n",
            "Epoch 78 Loss 5.004666\n",
            "Time taken for 1 epoch 64.94430494308472 sec\n",
            "\n",
            "Epoch 79 Batch 0 Loss 0.1294\n",
            "Epoch 79 Batch 0 Accuracy 0.0033\n",
            "Epoch 79 Batch 50 Loss 0.1265\n",
            "Epoch 79 Batch 50 Accuracy 0.0033\n",
            "Epoch 79 Batch 100 Loss 0.1266\n",
            "Epoch 79 Batch 100 Accuracy 0.0035\n",
            "Epoch 79 Batch 150 Loss 0.1284\n",
            "Epoch 79 Batch 150 Accuracy 0.0034\n",
            "Epoch 79 Batch 200 Loss 0.1264\n",
            "Epoch 79 Batch 200 Accuracy 0.0035\n",
            "Epoch 79 Loss 5.004780\n",
            "Time taken for 1 epoch 65.09752058982849 sec\n",
            "\n",
            "Epoch 80 Batch 0 Loss 0.1259\n",
            "Epoch 80 Batch 0 Accuracy 0.0034\n",
            "Epoch 80 Batch 50 Loss 0.1287\n",
            "Epoch 80 Batch 50 Accuracy 0.0031\n",
            "Epoch 80 Batch 100 Loss 0.1276\n",
            "Epoch 80 Batch 100 Accuracy 0.0037\n",
            "Epoch 80 Batch 150 Loss 0.1274\n",
            "Epoch 80 Batch 150 Accuracy 0.0036\n",
            "Epoch 80 Batch 200 Loss 0.1273\n",
            "Epoch 80 Batch 200 Accuracy 0.0033\n",
            "Epoch 80 Loss 5.003913\n",
            "Time taken for 1 epoch 65.67262125015259 sec\n",
            "\n",
            "Epoch 81 Batch 0 Loss 0.1262\n",
            "Epoch 81 Batch 0 Accuracy 0.0038\n",
            "Epoch 81 Batch 50 Loss 0.1280\n",
            "Epoch 81 Batch 50 Accuracy 0.0036\n",
            "Epoch 81 Batch 100 Loss 0.1265\n",
            "Epoch 81 Batch 100 Accuracy 0.0038\n",
            "Epoch 81 Batch 150 Loss 0.1283\n",
            "Epoch 81 Batch 150 Accuracy 0.0033\n",
            "Epoch 81 Batch 200 Loss 0.1267\n",
            "Epoch 81 Batch 200 Accuracy 0.0033\n",
            "Epoch 81 Loss 5.004283\n",
            "Time taken for 1 epoch 66.43986368179321 sec\n",
            "\n",
            "Epoch 82 Batch 0 Loss 0.1257\n",
            "Epoch 82 Batch 0 Accuracy 0.0034\n",
            "Epoch 82 Batch 50 Loss 0.1284\n",
            "Epoch 82 Batch 50 Accuracy 0.0036\n",
            "Epoch 82 Batch 100 Loss 0.1269\n",
            "Epoch 82 Batch 100 Accuracy 0.0037\n",
            "Epoch 82 Batch 150 Loss 0.1285\n",
            "Epoch 82 Batch 150 Accuracy 0.0036\n",
            "Epoch 82 Batch 200 Loss 0.1280\n",
            "Epoch 82 Batch 200 Accuracy 0.0036\n",
            "Epoch 82 Loss 5.005131\n",
            "Time taken for 1 epoch 66.25435376167297 sec\n",
            "\n",
            "Epoch 83 Batch 0 Loss 0.1296\n",
            "Epoch 83 Batch 0 Accuracy 0.0033\n",
            "Epoch 83 Batch 50 Loss 0.1284\n",
            "Epoch 83 Batch 50 Accuracy 0.0035\n",
            "Epoch 83 Batch 100 Loss 0.1278\n",
            "Epoch 83 Batch 100 Accuracy 0.0034\n",
            "Epoch 83 Batch 150 Loss 0.1285\n",
            "Epoch 83 Batch 150 Accuracy 0.0035\n",
            "Epoch 83 Batch 200 Loss 0.1258\n",
            "Epoch 83 Batch 200 Accuracy 0.0036\n",
            "Epoch 83 Loss 5.004434\n",
            "Time taken for 1 epoch 66.67543029785156 sec\n",
            "\n",
            "Epoch 84 Batch 0 Loss 0.1287\n",
            "Epoch 84 Batch 0 Accuracy 0.0033\n",
            "Epoch 84 Batch 50 Loss 0.1267\n",
            "Epoch 84 Batch 50 Accuracy 0.0038\n",
            "Epoch 84 Batch 100 Loss 0.1282\n",
            "Epoch 84 Batch 100 Accuracy 0.0034\n",
            "Epoch 84 Batch 150 Loss 0.1285\n",
            "Epoch 84 Batch 150 Accuracy 0.0035\n",
            "Epoch 84 Batch 200 Loss 0.1248\n",
            "Epoch 84 Batch 200 Accuracy 0.0037\n",
            "Epoch 84 Loss 5.004638\n",
            "Time taken for 1 epoch 66.62754392623901 sec\n",
            "\n",
            "Epoch 85 Batch 0 Loss 0.1283\n",
            "Epoch 85 Batch 0 Accuracy 0.0035\n",
            "Epoch 85 Batch 50 Loss 0.1295\n",
            "Epoch 85 Batch 50 Accuracy 0.0031\n",
            "Epoch 85 Batch 100 Loss 0.1288\n",
            "Epoch 85 Batch 100 Accuracy 0.0037\n",
            "Epoch 85 Batch 150 Loss 0.1279\n",
            "Epoch 85 Batch 150 Accuracy 0.0035\n",
            "Epoch 85 Batch 200 Loss 0.1289\n",
            "Epoch 85 Batch 200 Accuracy 0.0034\n",
            "Epoch 85 Loss 5.004247\n",
            "Time taken for 1 epoch 66.21071410179138 sec\n",
            "\n",
            "Epoch 86 Batch 0 Loss 0.1291\n",
            "Epoch 86 Batch 0 Accuracy 0.0034\n",
            "Epoch 86 Batch 50 Loss 0.1285\n",
            "Epoch 86 Batch 50 Accuracy 0.0033\n",
            "Epoch 86 Batch 100 Loss 0.1275\n",
            "Epoch 86 Batch 100 Accuracy 0.0037\n",
            "Epoch 86 Batch 150 Loss 0.1289\n",
            "Epoch 86 Batch 150 Accuracy 0.0035\n",
            "Epoch 86 Batch 200 Loss 0.1286\n",
            "Epoch 86 Batch 200 Accuracy 0.0034\n",
            "Epoch 86 Loss 5.004112\n",
            "Time taken for 1 epoch 65.90858960151672 sec\n",
            "\n",
            "Epoch 87 Batch 0 Loss 0.1291\n",
            "Epoch 87 Batch 0 Accuracy 0.0033\n",
            "Epoch 87 Batch 50 Loss 0.1282\n",
            "Epoch 87 Batch 50 Accuracy 0.0035\n",
            "Epoch 87 Batch 100 Loss 0.1279\n",
            "Epoch 87 Batch 100 Accuracy 0.0035\n",
            "Epoch 87 Batch 150 Loss 0.1269\n",
            "Epoch 87 Batch 150 Accuracy 0.0036\n",
            "Epoch 87 Batch 200 Loss 0.1265\n",
            "Epoch 87 Batch 200 Accuracy 0.0036\n",
            "Epoch 87 Loss 5.004698\n",
            "Time taken for 1 epoch 65.20640206336975 sec\n",
            "\n",
            "Epoch 88 Batch 0 Loss 0.1269\n",
            "Epoch 88 Batch 0 Accuracy 0.0034\n",
            "Epoch 88 Batch 50 Loss 0.1265\n",
            "Epoch 88 Batch 50 Accuracy 0.0035\n",
            "Epoch 88 Batch 100 Loss 0.1273\n",
            "Epoch 88 Batch 100 Accuracy 0.0036\n",
            "Epoch 88 Batch 150 Loss 0.1273\n",
            "Epoch 88 Batch 150 Accuracy 0.0036\n",
            "Epoch 88 Batch 200 Loss 0.1248\n",
            "Epoch 88 Batch 200 Accuracy 0.0033\n",
            "Epoch 88 Loss 5.004146\n",
            "Time taken for 1 epoch 64.591548204422 sec\n",
            "\n",
            "Epoch 89 Batch 0 Loss 0.1268\n",
            "Epoch 89 Batch 0 Accuracy 0.0035\n",
            "Epoch 89 Batch 50 Loss 0.1281\n",
            "Epoch 89 Batch 50 Accuracy 0.0035\n",
            "Epoch 89 Batch 100 Loss 0.1254\n",
            "Epoch 89 Batch 100 Accuracy 0.0036\n",
            "Epoch 89 Batch 150 Loss 0.1273\n",
            "Epoch 89 Batch 150 Accuracy 0.0034\n",
            "Epoch 89 Batch 200 Loss 0.1269\n",
            "Epoch 89 Batch 200 Accuracy 0.0034\n",
            "Epoch 89 Loss 5.004807\n",
            "Time taken for 1 epoch 64.46513175964355 sec\n",
            "\n",
            "Epoch 90 Batch 0 Loss 0.1277\n",
            "Epoch 90 Batch 0 Accuracy 0.0034\n",
            "Epoch 90 Batch 50 Loss 0.1275\n",
            "Epoch 90 Batch 50 Accuracy 0.0034\n",
            "Epoch 90 Batch 100 Loss 0.1269\n",
            "Epoch 90 Batch 100 Accuracy 0.0039\n",
            "Epoch 90 Batch 150 Loss 0.1281\n",
            "Epoch 90 Batch 150 Accuracy 0.0037\n",
            "Epoch 90 Batch 200 Loss 0.1290\n",
            "Epoch 90 Batch 200 Accuracy 0.0034\n",
            "Epoch 90 Loss 5.005283\n",
            "Time taken for 1 epoch 64.3946144580841 sec\n",
            "\n",
            "Epoch 91 Batch 0 Loss 0.1255\n",
            "Epoch 91 Batch 0 Accuracy 0.0034\n",
            "Epoch 91 Batch 50 Loss 0.1278\n",
            "Epoch 91 Batch 50 Accuracy 0.0037\n",
            "Epoch 91 Batch 100 Loss 0.1278\n",
            "Epoch 91 Batch 100 Accuracy 0.0034\n",
            "Epoch 91 Batch 150 Loss 0.1265\n",
            "Epoch 91 Batch 150 Accuracy 0.0035\n",
            "Epoch 91 Batch 200 Loss 0.1295\n",
            "Epoch 91 Batch 200 Accuracy 0.0035\n",
            "Epoch 91 Loss 5.004776\n",
            "Time taken for 1 epoch 65.27423739433289 sec\n",
            "\n",
            "Epoch 92 Batch 0 Loss 0.1292\n",
            "Epoch 92 Batch 0 Accuracy 0.0033\n",
            "Epoch 92 Batch 50 Loss 0.1282\n",
            "Epoch 92 Batch 50 Accuracy 0.0035\n",
            "Epoch 92 Batch 100 Loss 0.1259\n",
            "Epoch 92 Batch 100 Accuracy 0.0036\n",
            "Epoch 92 Batch 150 Loss 0.1279\n",
            "Epoch 92 Batch 150 Accuracy 0.0033\n",
            "Epoch 92 Batch 200 Loss 0.1290\n",
            "Epoch 92 Batch 200 Accuracy 0.0031\n",
            "Epoch 92 Loss 5.004688\n",
            "Time taken for 1 epoch 64.6406364440918 sec\n",
            "\n",
            "Epoch 93 Batch 0 Loss 0.1280\n",
            "Epoch 93 Batch 0 Accuracy 0.0034\n",
            "Epoch 93 Batch 50 Loss 0.1268\n",
            "Epoch 93 Batch 50 Accuracy 0.0036\n",
            "Epoch 93 Batch 100 Loss 0.1261\n",
            "Epoch 93 Batch 100 Accuracy 0.0034\n",
            "Epoch 93 Batch 150 Loss 0.1271\n",
            "Epoch 93 Batch 150 Accuracy 0.0035\n",
            "Epoch 93 Batch 200 Loss 0.1270\n",
            "Epoch 93 Batch 200 Accuracy 0.0032\n",
            "Epoch 93 Loss 5.003536\n",
            "Time taken for 1 epoch 64.4874906539917 sec\n",
            "\n",
            "Epoch 94 Batch 0 Loss 0.1278\n",
            "Epoch 94 Batch 0 Accuracy 0.0036\n",
            "Epoch 94 Batch 50 Loss 0.1280\n",
            "Epoch 94 Batch 50 Accuracy 0.0034\n",
            "Epoch 94 Batch 100 Loss 0.1273\n",
            "Epoch 94 Batch 100 Accuracy 0.0036\n",
            "Epoch 94 Batch 150 Loss 0.1286\n",
            "Epoch 94 Batch 150 Accuracy 0.0037\n",
            "Epoch 94 Batch 200 Loss 0.1268\n",
            "Epoch 94 Batch 200 Accuracy 0.0034\n",
            "Epoch 94 Loss 5.004304\n",
            "Time taken for 1 epoch 64.28087735176086 sec\n",
            "\n",
            "Epoch 95 Batch 0 Loss 0.1262\n",
            "Epoch 95 Batch 0 Accuracy 0.0033\n",
            "Epoch 95 Batch 50 Loss 0.1274\n",
            "Epoch 95 Batch 50 Accuracy 0.0037\n",
            "Epoch 95 Batch 100 Loss 0.1289\n",
            "Epoch 95 Batch 100 Accuracy 0.0035\n",
            "Epoch 95 Batch 150 Loss 0.1273\n",
            "Epoch 95 Batch 150 Accuracy 0.0034\n",
            "Epoch 95 Batch 200 Loss 0.1273\n",
            "Epoch 95 Batch 200 Accuracy 0.0032\n",
            "Epoch 95 Loss 5.004617\n",
            "Time taken for 1 epoch 64.50131821632385 sec\n",
            "\n",
            "Epoch 96 Batch 0 Loss 0.1265\n",
            "Epoch 96 Batch 0 Accuracy 0.0035\n",
            "Epoch 96 Batch 50 Loss 0.1274\n",
            "Epoch 96 Batch 50 Accuracy 0.0035\n",
            "Epoch 96 Batch 100 Loss 0.1256\n",
            "Epoch 96 Batch 100 Accuracy 0.0038\n",
            "Epoch 96 Batch 150 Loss 0.1301\n",
            "Epoch 96 Batch 150 Accuracy 0.0034\n",
            "Epoch 96 Batch 200 Loss 0.1268\n",
            "Epoch 96 Batch 200 Accuracy 0.0036\n",
            "Epoch 96 Loss 5.004096\n",
            "Time taken for 1 epoch 64.70755410194397 sec\n",
            "\n",
            "Epoch 97 Batch 0 Loss 0.1286\n",
            "Epoch 97 Batch 0 Accuracy 0.0035\n",
            "Epoch 97 Batch 50 Loss 0.1279\n",
            "Epoch 97 Batch 50 Accuracy 0.0034\n",
            "Epoch 97 Batch 100 Loss 0.1275\n",
            "Epoch 97 Batch 100 Accuracy 0.0035\n",
            "Epoch 97 Batch 150 Loss 0.1289\n",
            "Epoch 97 Batch 150 Accuracy 0.0039\n",
            "Epoch 97 Batch 200 Loss 0.1266\n",
            "Epoch 97 Batch 200 Accuracy 0.0035\n",
            "Epoch 97 Loss 5.004215\n",
            "Time taken for 1 epoch 64.54279494285583 sec\n",
            "\n",
            "Epoch 98 Batch 0 Loss 0.1290\n",
            "Epoch 98 Batch 0 Accuracy 0.0033\n",
            "Epoch 98 Batch 50 Loss 0.1298\n",
            "Epoch 98 Batch 50 Accuracy 0.0035\n",
            "Epoch 98 Batch 100 Loss 0.1288\n",
            "Epoch 98 Batch 100 Accuracy 0.0035\n",
            "Epoch 98 Batch 150 Loss 0.1261\n",
            "Epoch 98 Batch 150 Accuracy 0.0036\n",
            "Epoch 98 Batch 200 Loss 0.1273\n",
            "Epoch 98 Batch 200 Accuracy 0.0035\n",
            "Epoch 98 Loss 5.004299\n",
            "Time taken for 1 epoch 64.18970155715942 sec\n",
            "\n",
            "Epoch 99 Batch 0 Loss 0.1291\n",
            "Epoch 99 Batch 0 Accuracy 0.0034\n",
            "Epoch 99 Batch 50 Loss 0.1266\n",
            "Epoch 99 Batch 50 Accuracy 0.0036\n",
            "Epoch 99 Batch 100 Loss 0.1280\n",
            "Epoch 99 Batch 100 Accuracy 0.0036\n",
            "Epoch 99 Batch 150 Loss 0.1263\n",
            "Epoch 99 Batch 150 Accuracy 0.0034\n",
            "Epoch 99 Batch 200 Loss 0.1288\n",
            "Epoch 99 Batch 200 Accuracy 0.0034\n",
            "Epoch 99 Loss 5.003345\n",
            "Time taken for 1 epoch 64.18192601203918 sec\n",
            "\n",
            "Epoch 100 Batch 0 Loss 0.1313\n",
            "Epoch 100 Batch 0 Accuracy 0.0033\n",
            "Epoch 100 Batch 50 Loss 0.1264\n",
            "Epoch 100 Batch 50 Accuracy 0.0036\n",
            "Epoch 100 Batch 100 Loss 0.1275\n",
            "Epoch 100 Batch 100 Accuracy 0.0034\n",
            "Epoch 100 Batch 150 Loss 0.1283\n",
            "Epoch 100 Batch 150 Accuracy 0.0034\n",
            "Epoch 100 Batch 200 Loss 0.1268\n",
            "Epoch 100 Batch 200 Accuracy 0.0035\n",
            "Epoch 100 Loss 5.002997\n",
            "Time taken for 1 epoch 64.64734482765198 sec\n",
            "\n",
            "Epoch 101 Batch 0 Loss 0.1301\n",
            "Epoch 101 Batch 0 Accuracy 0.0034\n",
            "Epoch 101 Batch 50 Loss 0.1279\n",
            "Epoch 101 Batch 50 Accuracy 0.0035\n",
            "Epoch 101 Batch 100 Loss 0.1285\n",
            "Epoch 101 Batch 100 Accuracy 0.0035\n",
            "Epoch 101 Batch 150 Loss 0.1297\n",
            "Epoch 101 Batch 150 Accuracy 0.0035\n",
            "Epoch 101 Batch 200 Loss 0.1285\n",
            "Epoch 101 Batch 200 Accuracy 0.0033\n",
            "Epoch 101 Loss 5.004365\n",
            "Time taken for 1 epoch 64.38998627662659 sec\n",
            "\n",
            "Epoch 102 Batch 0 Loss 0.1273\n",
            "Epoch 102 Batch 0 Accuracy 0.0037\n",
            "Epoch 102 Batch 50 Loss 0.1269\n",
            "Epoch 102 Batch 50 Accuracy 0.0035\n",
            "Epoch 102 Batch 100 Loss 0.1284\n",
            "Epoch 102 Batch 100 Accuracy 0.0036\n",
            "Epoch 102 Batch 150 Loss 0.1283\n",
            "Epoch 102 Batch 150 Accuracy 0.0036\n",
            "Epoch 102 Batch 200 Loss 0.1268\n",
            "Epoch 102 Batch 200 Accuracy 0.0036\n",
            "Epoch 102 Loss 5.005075\n",
            "Time taken for 1 epoch 64.42968463897705 sec\n",
            "\n",
            "Epoch 103 Batch 0 Loss 0.1267\n",
            "Epoch 103 Batch 0 Accuracy 0.0034\n",
            "Epoch 103 Batch 50 Loss 0.1291\n",
            "Epoch 103 Batch 50 Accuracy 0.0032\n",
            "Epoch 103 Batch 100 Loss 0.1266\n",
            "Epoch 103 Batch 100 Accuracy 0.0036\n",
            "Epoch 103 Batch 150 Loss 0.1269\n",
            "Epoch 103 Batch 150 Accuracy 0.0035\n",
            "Epoch 103 Batch 200 Loss 0.1279\n",
            "Epoch 103 Batch 200 Accuracy 0.0035\n",
            "Epoch 103 Loss 5.004541\n",
            "Time taken for 1 epoch 64.20815229415894 sec\n",
            "\n",
            "Epoch 104 Batch 0 Loss 0.1265\n",
            "Epoch 104 Batch 0 Accuracy 0.0038\n",
            "Epoch 104 Batch 50 Loss 0.1273\n",
            "Epoch 104 Batch 50 Accuracy 0.0034\n",
            "Epoch 104 Batch 100 Loss 0.1262\n",
            "Epoch 104 Batch 100 Accuracy 0.0035\n",
            "Epoch 104 Batch 150 Loss 0.1268\n",
            "Epoch 104 Batch 150 Accuracy 0.0035\n",
            "Epoch 104 Batch 200 Loss 0.1280\n",
            "Epoch 104 Batch 200 Accuracy 0.0034\n",
            "Epoch 104 Loss 5.003203\n",
            "Time taken for 1 epoch 64.27213501930237 sec\n",
            "\n",
            "Epoch 105 Batch 0 Loss 0.1272\n",
            "Epoch 105 Batch 0 Accuracy 0.0034\n",
            "Epoch 105 Batch 50 Loss 0.1287\n",
            "Epoch 105 Batch 50 Accuracy 0.0033\n",
            "Epoch 105 Batch 100 Loss 0.1256\n",
            "Epoch 105 Batch 100 Accuracy 0.0036\n",
            "Epoch 105 Batch 150 Loss 0.1256\n",
            "Epoch 105 Batch 150 Accuracy 0.0035\n",
            "Epoch 105 Batch 200 Loss 0.1282\n",
            "Epoch 105 Batch 200 Accuracy 0.0032\n",
            "Epoch 105 Loss 5.002423\n",
            "Time taken for 1 epoch 64.90871834754944 sec\n",
            "\n",
            "Epoch 106 Batch 0 Loss 0.1290\n",
            "Epoch 106 Batch 0 Accuracy 0.0034\n",
            "Epoch 106 Batch 50 Loss 0.1267\n",
            "Epoch 106 Batch 50 Accuracy 0.0035\n",
            "Epoch 106 Batch 100 Loss 0.1286\n",
            "Epoch 106 Batch 100 Accuracy 0.0035\n",
            "Epoch 106 Batch 150 Loss 0.1274\n",
            "Epoch 106 Batch 150 Accuracy 0.0037\n",
            "Epoch 106 Batch 200 Loss 0.1256\n",
            "Epoch 106 Batch 200 Accuracy 0.0034\n",
            "Epoch 106 Loss 5.002378\n",
            "Time taken for 1 epoch 64.84616684913635 sec\n",
            "\n",
            "Epoch 107 Batch 0 Loss 0.1263\n",
            "Epoch 107 Batch 0 Accuracy 0.0036\n",
            "Epoch 107 Batch 50 Loss 0.1275\n",
            "Epoch 107 Batch 50 Accuracy 0.0031\n",
            "Epoch 107 Batch 100 Loss 0.1285\n",
            "Epoch 107 Batch 100 Accuracy 0.0034\n",
            "Epoch 107 Batch 150 Loss 0.1283\n",
            "Epoch 107 Batch 150 Accuracy 0.0033\n",
            "Epoch 107 Batch 200 Loss 0.1278\n",
            "Epoch 107 Batch 200 Accuracy 0.0034\n",
            "Epoch 107 Loss 5.004502\n",
            "Time taken for 1 epoch 64.46067714691162 sec\n",
            "\n",
            "Epoch 108 Batch 0 Loss 0.1293\n",
            "Epoch 108 Batch 0 Accuracy 0.0034\n",
            "Epoch 108 Batch 50 Loss 0.1279\n",
            "Epoch 108 Batch 50 Accuracy 0.0034\n",
            "Epoch 108 Batch 100 Loss 0.1264\n",
            "Epoch 108 Batch 100 Accuracy 0.0035\n",
            "Epoch 108 Batch 150 Loss 0.1290\n",
            "Epoch 108 Batch 150 Accuracy 0.0033\n",
            "Epoch 108 Batch 200 Loss 0.1285\n",
            "Epoch 108 Batch 200 Accuracy 0.0032\n",
            "Epoch 108 Loss 5.004016\n",
            "Time taken for 1 epoch 64.65344285964966 sec\n",
            "\n",
            "Epoch 109 Batch 0 Loss 0.1271\n",
            "Epoch 109 Batch 0 Accuracy 0.0035\n",
            "Epoch 109 Batch 50 Loss 0.1269\n",
            "Epoch 109 Batch 50 Accuracy 0.0036\n",
            "Epoch 109 Batch 100 Loss 0.1260\n",
            "Epoch 109 Batch 100 Accuracy 0.0035\n",
            "Epoch 109 Batch 150 Loss 0.1274\n",
            "Epoch 109 Batch 150 Accuracy 0.0035\n",
            "Epoch 109 Batch 200 Loss 0.1295\n",
            "Epoch 109 Batch 200 Accuracy 0.0032\n",
            "Epoch 109 Loss 5.005827\n",
            "Time taken for 1 epoch 64.61997246742249 sec\n",
            "\n",
            "Epoch 110 Batch 0 Loss 0.1294\n",
            "Epoch 110 Batch 0 Accuracy 0.0033\n",
            "Epoch 110 Batch 50 Loss 0.1285\n",
            "Epoch 110 Batch 50 Accuracy 0.0035\n",
            "Epoch 110 Batch 100 Loss 0.1273\n",
            "Epoch 110 Batch 100 Accuracy 0.0035\n",
            "Epoch 110 Batch 150 Loss 0.1255\n",
            "Epoch 110 Batch 150 Accuracy 0.0037\n",
            "Epoch 110 Batch 200 Loss 0.1293\n",
            "Epoch 110 Batch 200 Accuracy 0.0032\n",
            "Epoch 110 Loss 5.002920\n",
            "Time taken for 1 epoch 65.26268148422241 sec\n",
            "\n",
            "Epoch 111 Batch 0 Loss 0.1266\n",
            "Epoch 111 Batch 0 Accuracy 0.0034\n",
            "Epoch 111 Batch 50 Loss 0.1276\n",
            "Epoch 111 Batch 50 Accuracy 0.0035\n",
            "Epoch 111 Batch 100 Loss 0.1297\n",
            "Epoch 111 Batch 100 Accuracy 0.0034\n",
            "Epoch 111 Batch 150 Loss 0.1292\n",
            "Epoch 111 Batch 150 Accuracy 0.0034\n",
            "Epoch 111 Batch 200 Loss 0.1282\n",
            "Epoch 111 Batch 200 Accuracy 0.0035\n",
            "Epoch 111 Loss 5.005363\n",
            "Time taken for 1 epoch 65.46201705932617 sec\n",
            "\n",
            "Epoch 112 Batch 0 Loss 0.1274\n",
            "Epoch 112 Batch 0 Accuracy 0.0034\n",
            "Epoch 112 Batch 50 Loss 0.1273\n",
            "Epoch 112 Batch 50 Accuracy 0.0035\n",
            "Epoch 112 Batch 100 Loss 0.1280\n",
            "Epoch 112 Batch 100 Accuracy 0.0035\n",
            "Epoch 112 Batch 150 Loss 0.1265\n",
            "Epoch 112 Batch 150 Accuracy 0.0036\n",
            "Epoch 112 Batch 200 Loss 0.1257\n",
            "Epoch 112 Batch 200 Accuracy 0.0034\n",
            "Epoch 112 Loss 5.004773\n",
            "Time taken for 1 epoch 65.69939661026001 sec\n",
            "\n",
            "Epoch 113 Batch 0 Loss 0.1274\n",
            "Epoch 113 Batch 0 Accuracy 0.0035\n",
            "Epoch 113 Batch 50 Loss 0.1302\n",
            "Epoch 113 Batch 50 Accuracy 0.0034\n",
            "Epoch 113 Batch 100 Loss 0.1287\n",
            "Epoch 113 Batch 100 Accuracy 0.0035\n",
            "Epoch 113 Batch 150 Loss 0.1266\n",
            "Epoch 113 Batch 150 Accuracy 0.0034\n",
            "Epoch 113 Batch 200 Loss 0.1303\n",
            "Epoch 113 Batch 200 Accuracy 0.0033\n",
            "Epoch 113 Loss 5.008628\n",
            "Time taken for 1 epoch 64.40689778327942 sec\n",
            "\n",
            "Epoch 114 Batch 0 Loss 0.1301\n",
            "Epoch 114 Batch 0 Accuracy 0.0036\n",
            "Epoch 114 Batch 50 Loss 0.1281\n",
            "Epoch 114 Batch 50 Accuracy 0.0037\n",
            "Epoch 114 Batch 100 Loss 0.1254\n",
            "Epoch 114 Batch 100 Accuracy 0.0037\n",
            "Epoch 114 Batch 150 Loss 0.1267\n",
            "Epoch 114 Batch 150 Accuracy 0.0035\n",
            "Epoch 114 Batch 200 Loss 0.1269\n",
            "Epoch 114 Batch 200 Accuracy 0.0035\n",
            "Epoch 114 Loss 5.005171\n",
            "Time taken for 1 epoch 65.49776816368103 sec\n",
            "\n",
            "Epoch 115 Batch 0 Loss 0.1288\n",
            "Epoch 115 Batch 0 Accuracy 0.0034\n",
            "Epoch 115 Batch 50 Loss 0.1257\n",
            "Epoch 115 Batch 50 Accuracy 0.0036\n",
            "Epoch 115 Batch 100 Loss 0.1283\n",
            "Epoch 115 Batch 100 Accuracy 0.0036\n",
            "Epoch 115 Batch 150 Loss 0.1279\n",
            "Epoch 115 Batch 150 Accuracy 0.0035\n",
            "Epoch 115 Batch 200 Loss 0.1266\n",
            "Epoch 115 Batch 200 Accuracy 0.0034\n",
            "Epoch 115 Loss 5.004704\n",
            "Time taken for 1 epoch 67.62826108932495 sec\n",
            "\n",
            "Epoch 116 Batch 0 Loss 0.1293\n",
            "Epoch 116 Batch 0 Accuracy 0.0033\n",
            "Epoch 116 Batch 50 Loss 0.1266\n",
            "Epoch 116 Batch 50 Accuracy 0.0036\n",
            "Epoch 116 Batch 100 Loss 0.1281\n",
            "Epoch 116 Batch 100 Accuracy 0.0033\n",
            "Epoch 116 Batch 150 Loss 0.1279\n",
            "Epoch 116 Batch 150 Accuracy 0.0036\n",
            "Epoch 116 Batch 200 Loss 0.1275\n",
            "Epoch 116 Batch 200 Accuracy 0.0032\n",
            "Epoch 116 Loss 5.003112\n",
            "Time taken for 1 epoch 68.29922389984131 sec\n",
            "\n",
            "Epoch 117 Batch 0 Loss 0.1287\n",
            "Epoch 117 Batch 0 Accuracy 0.0033\n",
            "Epoch 117 Batch 50 Loss 0.1291\n",
            "Epoch 117 Batch 50 Accuracy 0.0038\n",
            "Epoch 117 Batch 100 Loss 0.1281\n",
            "Epoch 117 Batch 100 Accuracy 0.0035\n",
            "Epoch 117 Batch 150 Loss 0.1276\n",
            "Epoch 117 Batch 150 Accuracy 0.0035\n",
            "Epoch 117 Batch 200 Loss 0.1262\n",
            "Epoch 117 Batch 200 Accuracy 0.0034\n",
            "Epoch 117 Loss 5.004166\n",
            "Time taken for 1 epoch 68.77868556976318 sec\n",
            "\n",
            "Epoch 118 Batch 0 Loss 0.1267\n",
            "Epoch 118 Batch 0 Accuracy 0.0035\n",
            "Epoch 118 Batch 50 Loss 0.1290\n",
            "Epoch 118 Batch 50 Accuracy 0.0032\n",
            "Epoch 118 Batch 100 Loss 0.1302\n",
            "Epoch 118 Batch 100 Accuracy 0.0035\n",
            "Epoch 118 Batch 150 Loss 0.1278\n",
            "Epoch 118 Batch 150 Accuracy 0.0035\n",
            "Epoch 118 Batch 200 Loss 0.1289\n",
            "Epoch 118 Batch 200 Accuracy 0.0032\n",
            "Epoch 118 Loss 5.003551\n",
            "Time taken for 1 epoch 68.91337776184082 sec\n",
            "\n",
            "Epoch 119 Batch 0 Loss 0.1294\n",
            "Epoch 119 Batch 0 Accuracy 0.0035\n",
            "Epoch 119 Batch 50 Loss 0.1287\n",
            "Epoch 119 Batch 50 Accuracy 0.0033\n",
            "Epoch 119 Batch 100 Loss 0.1272\n",
            "Epoch 119 Batch 100 Accuracy 0.0036\n",
            "Epoch 119 Batch 150 Loss 0.1256\n",
            "Epoch 119 Batch 150 Accuracy 0.0036\n",
            "Epoch 119 Batch 200 Loss 0.1287\n",
            "Epoch 119 Batch 200 Accuracy 0.0037\n",
            "Epoch 119 Loss 5.005371\n",
            "Time taken for 1 epoch 69.79113626480103 sec\n",
            "\n",
            "Epoch 120 Batch 0 Loss 0.1305\n",
            "Epoch 120 Batch 0 Accuracy 0.0033\n",
            "Epoch 120 Batch 50 Loss 0.1289\n",
            "Epoch 120 Batch 50 Accuracy 0.0035\n",
            "Epoch 120 Batch 100 Loss 0.1261\n",
            "Epoch 120 Batch 100 Accuracy 0.0034\n",
            "Epoch 120 Batch 150 Loss 0.1268\n",
            "Epoch 120 Batch 150 Accuracy 0.0038\n",
            "Epoch 120 Batch 200 Loss 0.1266\n",
            "Epoch 120 Batch 200 Accuracy 0.0035\n",
            "Epoch 120 Loss 5.003073\n",
            "Time taken for 1 epoch 69.43451762199402 sec\n",
            "\n",
            "Epoch 121 Batch 0 Loss 0.1310\n",
            "Epoch 121 Batch 0 Accuracy 0.0034\n",
            "Epoch 121 Batch 50 Loss 0.1298\n",
            "Epoch 121 Batch 50 Accuracy 0.0033\n",
            "Epoch 121 Batch 100 Loss 0.1285\n",
            "Epoch 121 Batch 100 Accuracy 0.0034\n",
            "Epoch 121 Batch 150 Loss 0.1293\n",
            "Epoch 121 Batch 150 Accuracy 0.0031\n",
            "Epoch 121 Batch 200 Loss 0.1274\n",
            "Epoch 121 Batch 200 Accuracy 0.0034\n",
            "Epoch 121 Loss 5.002525\n",
            "Time taken for 1 epoch 69.75790357589722 sec\n",
            "\n",
            "Epoch 122 Batch 0 Loss 0.1303\n",
            "Epoch 122 Batch 0 Accuracy 0.0034\n",
            "Epoch 122 Batch 50 Loss 0.1273\n",
            "Epoch 122 Batch 50 Accuracy 0.0037\n",
            "Epoch 122 Batch 100 Loss 0.1256\n",
            "Epoch 122 Batch 100 Accuracy 0.0036\n",
            "Epoch 122 Batch 150 Loss 0.1262\n",
            "Epoch 122 Batch 150 Accuracy 0.0035\n",
            "Epoch 122 Batch 200 Loss 0.1292\n",
            "Epoch 122 Batch 200 Accuracy 0.0034\n",
            "Epoch 122 Loss 5.001885\n",
            "Time taken for 1 epoch 68.91612434387207 sec\n",
            "\n",
            "Epoch 123 Batch 0 Loss 0.1291\n",
            "Epoch 123 Batch 0 Accuracy 0.0033\n",
            "Epoch 123 Batch 50 Loss 0.1287\n",
            "Epoch 123 Batch 50 Accuracy 0.0033\n",
            "Epoch 123 Batch 100 Loss 0.1260\n",
            "Epoch 123 Batch 100 Accuracy 0.0036\n",
            "Epoch 123 Batch 150 Loss 0.1246\n",
            "Epoch 123 Batch 150 Accuracy 0.0036\n",
            "Epoch 123 Batch 200 Loss 0.1272\n",
            "Epoch 123 Batch 200 Accuracy 0.0034\n",
            "Epoch 123 Loss 5.001936\n",
            "Time taken for 1 epoch 67.10610747337341 sec\n",
            "\n",
            "Epoch 124 Batch 0 Loss 0.1307\n",
            "Epoch 124 Batch 0 Accuracy 0.0032\n",
            "Epoch 124 Batch 50 Loss 0.1284\n",
            "Epoch 124 Batch 50 Accuracy 0.0035\n",
            "Epoch 124 Batch 100 Loss 0.1263\n",
            "Epoch 124 Batch 100 Accuracy 0.0034\n",
            "Epoch 124 Batch 150 Loss 0.1294\n",
            "Epoch 124 Batch 150 Accuracy 0.0034\n",
            "Epoch 124 Batch 200 Loss 0.1272\n",
            "Epoch 124 Batch 200 Accuracy 0.0036\n",
            "Epoch 124 Loss 5.004460\n",
            "Time taken for 1 epoch 66.85343503952026 sec\n",
            "\n",
            "Epoch 125 Batch 0 Loss 0.1282\n",
            "Epoch 125 Batch 0 Accuracy 0.0033\n",
            "Epoch 125 Batch 50 Loss 0.1278\n",
            "Epoch 125 Batch 50 Accuracy 0.0034\n",
            "Epoch 125 Batch 100 Loss 0.1271\n",
            "Epoch 125 Batch 100 Accuracy 0.0036\n",
            "Epoch 125 Batch 150 Loss 0.1289\n",
            "Epoch 125 Batch 150 Accuracy 0.0036\n",
            "Epoch 125 Batch 200 Loss 0.1240\n",
            "Epoch 125 Batch 200 Accuracy 0.0037\n",
            "Epoch 125 Loss 5.005282\n",
            "Time taken for 1 epoch 66.5938606262207 sec\n",
            "\n",
            "Epoch 126 Batch 0 Loss 0.1284\n",
            "Epoch 126 Batch 0 Accuracy 0.0034\n",
            "Epoch 126 Batch 50 Loss 0.1268\n",
            "Epoch 126 Batch 50 Accuracy 0.0035\n",
            "Epoch 126 Batch 100 Loss 0.1270\n",
            "Epoch 126 Batch 100 Accuracy 0.0036\n",
            "Epoch 126 Batch 150 Loss 0.1287\n",
            "Epoch 126 Batch 150 Accuracy 0.0035\n",
            "Epoch 126 Batch 200 Loss 0.1279\n",
            "Epoch 126 Batch 200 Accuracy 0.0032\n",
            "Epoch 126 Loss 5.004048\n",
            "Time taken for 1 epoch 65.967538356781 sec\n",
            "\n",
            "Epoch 127 Batch 0 Loss 0.1283\n",
            "Epoch 127 Batch 0 Accuracy 0.0034\n",
            "Epoch 127 Batch 50 Loss 0.1257\n",
            "Epoch 127 Batch 50 Accuracy 0.0038\n",
            "Epoch 127 Batch 100 Loss 0.1276\n",
            "Epoch 127 Batch 100 Accuracy 0.0036\n",
            "Epoch 127 Batch 150 Loss 0.1287\n",
            "Epoch 127 Batch 150 Accuracy 0.0035\n",
            "Epoch 127 Batch 200 Loss 0.1285\n",
            "Epoch 127 Batch 200 Accuracy 0.0034\n",
            "Epoch 127 Loss 5.004875\n",
            "Time taken for 1 epoch 65.53763771057129 sec\n",
            "\n",
            "Epoch 128 Batch 0 Loss 0.1288\n",
            "Epoch 128 Batch 0 Accuracy 0.0034\n",
            "Epoch 128 Batch 50 Loss 0.1262\n",
            "Epoch 128 Batch 50 Accuracy 0.0036\n",
            "Epoch 128 Batch 100 Loss 0.1265\n",
            "Epoch 128 Batch 100 Accuracy 0.0035\n",
            "Epoch 128 Batch 150 Loss 0.1260\n",
            "Epoch 128 Batch 150 Accuracy 0.0038\n",
            "Epoch 128 Batch 200 Loss 0.1256\n",
            "Epoch 128 Batch 200 Accuracy 0.0038\n",
            "Epoch 128 Loss 5.005239\n",
            "Time taken for 1 epoch 66.29716753959656 sec\n",
            "\n",
            "Epoch 129 Batch 0 Loss 0.1279\n",
            "Epoch 129 Batch 0 Accuracy 0.0034\n",
            "Epoch 129 Batch 50 Loss 0.1250\n",
            "Epoch 129 Batch 50 Accuracy 0.0036\n",
            "Epoch 129 Batch 100 Loss 0.1299\n",
            "Epoch 129 Batch 100 Accuracy 0.0034\n",
            "Epoch 129 Batch 150 Loss 0.1281\n",
            "Epoch 129 Batch 150 Accuracy 0.0035\n",
            "Epoch 129 Batch 200 Loss 0.1280\n",
            "Epoch 129 Batch 200 Accuracy 0.0034\n",
            "Epoch 129 Loss 5.004334\n",
            "Time taken for 1 epoch 64.73098707199097 sec\n",
            "\n",
            "Epoch 130 Batch 0 Loss 0.1289\n",
            "Epoch 130 Batch 0 Accuracy 0.0034\n",
            "Epoch 130 Batch 50 Loss 0.1277\n",
            "Epoch 130 Batch 50 Accuracy 0.0036\n",
            "Epoch 130 Batch 100 Loss 0.1285\n",
            "Epoch 130 Batch 100 Accuracy 0.0036\n",
            "Epoch 130 Batch 150 Loss 0.1255\n",
            "Epoch 130 Batch 150 Accuracy 0.0036\n",
            "Epoch 130 Batch 200 Loss 0.1258\n",
            "Epoch 130 Batch 200 Accuracy 0.0034\n",
            "Epoch 130 Loss 5.005311\n",
            "Time taken for 1 epoch 64.518146276474 sec\n",
            "\n",
            "Epoch 131 Batch 0 Loss 0.1279\n",
            "Epoch 131 Batch 0 Accuracy 0.0036\n",
            "Epoch 131 Batch 50 Loss 0.1284\n",
            "Epoch 131 Batch 50 Accuracy 0.0036\n",
            "Epoch 131 Batch 100 Loss 0.1281\n",
            "Epoch 131 Batch 100 Accuracy 0.0036\n",
            "Epoch 131 Batch 150 Loss 0.1275\n",
            "Epoch 131 Batch 150 Accuracy 0.0033\n",
            "Epoch 131 Batch 200 Loss 0.1270\n",
            "Epoch 131 Batch 200 Accuracy 0.0035\n",
            "Epoch 131 Loss 5.002058\n",
            "Time taken for 1 epoch 65.12556266784668 sec\n",
            "\n",
            "Epoch 132 Batch 0 Loss 0.1266\n",
            "Epoch 132 Batch 0 Accuracy 0.0034\n",
            "Epoch 132 Batch 50 Loss 0.1300\n",
            "Epoch 132 Batch 50 Accuracy 0.0033\n",
            "Epoch 132 Batch 100 Loss 0.1275\n",
            "Epoch 132 Batch 100 Accuracy 0.0035\n",
            "Epoch 132 Batch 150 Loss 0.1288\n",
            "Epoch 132 Batch 150 Accuracy 0.0034\n",
            "Epoch 132 Batch 200 Loss 0.1264\n",
            "Epoch 132 Batch 200 Accuracy 0.0034\n",
            "Epoch 132 Loss 5.003783\n",
            "Time taken for 1 epoch 67.4885766506195 sec\n",
            "\n",
            "Epoch 133 Batch 0 Loss 0.1274\n",
            "Epoch 133 Batch 0 Accuracy 0.0037\n",
            "Epoch 133 Batch 50 Loss 0.1303\n",
            "Epoch 133 Batch 50 Accuracy 0.0032\n",
            "Epoch 133 Batch 100 Loss 0.1260\n",
            "Epoch 133 Batch 100 Accuracy 0.0037\n",
            "Epoch 133 Batch 150 Loss 0.1269\n",
            "Epoch 133 Batch 150 Accuracy 0.0035\n",
            "Epoch 133 Batch 200 Loss 0.1319\n",
            "Epoch 133 Batch 200 Accuracy 0.0030\n",
            "Epoch 133 Loss 5.003839\n",
            "Time taken for 1 epoch 69.00732278823853 sec\n",
            "\n",
            "Epoch 134 Batch 0 Loss 0.1309\n",
            "Epoch 134 Batch 0 Accuracy 0.0035\n",
            "Epoch 134 Batch 50 Loss 0.1294\n",
            "Epoch 134 Batch 50 Accuracy 0.0034\n",
            "Epoch 134 Batch 100 Loss 0.1289\n",
            "Epoch 134 Batch 100 Accuracy 0.0035\n",
            "Epoch 134 Batch 150 Loss 0.1282\n",
            "Epoch 134 Batch 150 Accuracy 0.0033\n",
            "Epoch 134 Batch 200 Loss 0.1275\n",
            "Epoch 134 Batch 200 Accuracy 0.0033\n",
            "Epoch 134 Loss 5.004750\n",
            "Time taken for 1 epoch 67.11088275909424 sec\n",
            "\n",
            "Epoch 135 Batch 0 Loss 0.1290\n",
            "Epoch 135 Batch 0 Accuracy 0.0035\n",
            "Epoch 135 Batch 50 Loss 0.1292\n",
            "Epoch 135 Batch 50 Accuracy 0.0034\n",
            "Epoch 135 Batch 100 Loss 0.1266\n",
            "Epoch 135 Batch 100 Accuracy 0.0034\n",
            "Epoch 135 Batch 150 Loss 0.1301\n",
            "Epoch 135 Batch 150 Accuracy 0.0033\n",
            "Epoch 135 Batch 200 Loss 0.1288\n",
            "Epoch 135 Batch 200 Accuracy 0.0037\n",
            "Epoch 135 Loss 5.003036\n",
            "Time taken for 1 epoch 65.9992105960846 sec\n",
            "\n",
            "Epoch 136 Batch 0 Loss 0.1305\n",
            "Epoch 136 Batch 0 Accuracy 0.0033\n",
            "Epoch 136 Batch 50 Loss 0.1291\n",
            "Epoch 136 Batch 50 Accuracy 0.0036\n",
            "Epoch 136 Batch 100 Loss 0.1276\n",
            "Epoch 136 Batch 100 Accuracy 0.0034\n",
            "Epoch 136 Batch 150 Loss 0.1292\n",
            "Epoch 136 Batch 150 Accuracy 0.0034\n",
            "Epoch 136 Batch 200 Loss 0.1259\n",
            "Epoch 136 Batch 200 Accuracy 0.0035\n",
            "Epoch 136 Loss 5.003836\n",
            "Time taken for 1 epoch 65.36458468437195 sec\n",
            "\n",
            "Epoch 137 Batch 0 Loss 0.1281\n",
            "Epoch 137 Batch 0 Accuracy 0.0035\n",
            "Epoch 137 Batch 50 Loss 0.1279\n",
            "Epoch 137 Batch 50 Accuracy 0.0035\n",
            "Epoch 137 Batch 100 Loss 0.1262\n",
            "Epoch 137 Batch 100 Accuracy 0.0036\n",
            "Epoch 137 Batch 150 Loss 0.1287\n",
            "Epoch 137 Batch 150 Accuracy 0.0034\n",
            "Epoch 137 Batch 200 Loss 0.1293\n",
            "Epoch 137 Batch 200 Accuracy 0.0032\n",
            "Epoch 137 Loss 5.005786\n",
            "Time taken for 1 epoch 64.5515353679657 sec\n",
            "\n",
            "Epoch 138 Batch 0 Loss 0.1300\n",
            "Epoch 138 Batch 0 Accuracy 0.0035\n",
            "Epoch 138 Batch 50 Loss 0.1281\n",
            "Epoch 138 Batch 50 Accuracy 0.0034\n",
            "Epoch 138 Batch 100 Loss 0.1282\n",
            "Epoch 138 Batch 100 Accuracy 0.0035\n",
            "Epoch 138 Batch 150 Loss 0.1276\n",
            "Epoch 138 Batch 150 Accuracy 0.0036\n",
            "Epoch 138 Batch 200 Loss 0.1254\n",
            "Epoch 138 Batch 200 Accuracy 0.0036\n",
            "Epoch 138 Loss 5.003808\n",
            "Time taken for 1 epoch 64.70913648605347 sec\n",
            "\n",
            "Epoch 139 Batch 0 Loss 0.1261\n",
            "Epoch 139 Batch 0 Accuracy 0.0034\n",
            "Epoch 139 Batch 50 Loss 0.1268\n",
            "Epoch 139 Batch 50 Accuracy 0.0032\n",
            "Epoch 139 Batch 100 Loss 0.1270\n",
            "Epoch 139 Batch 100 Accuracy 0.0035\n",
            "Epoch 139 Batch 150 Loss 0.1269\n",
            "Epoch 139 Batch 150 Accuracy 0.0036\n",
            "Epoch 139 Batch 200 Loss 0.1262\n",
            "Epoch 139 Batch 200 Accuracy 0.0033\n",
            "Epoch 139 Loss 5.003498\n",
            "Time taken for 1 epoch 63.890974044799805 sec\n",
            "\n",
            "Epoch 140 Batch 0 Loss 0.1272\n",
            "Epoch 140 Batch 0 Accuracy 0.0034\n",
            "Epoch 140 Batch 50 Loss 0.1285\n",
            "Epoch 140 Batch 50 Accuracy 0.0036\n",
            "Epoch 140 Batch 100 Loss 0.1282\n",
            "Epoch 140 Batch 100 Accuracy 0.0036\n",
            "Epoch 140 Batch 150 Loss 0.1260\n",
            "Epoch 140 Batch 150 Accuracy 0.0037\n",
            "Epoch 140 Batch 200 Loss 0.1289\n",
            "Epoch 140 Batch 200 Accuracy 0.0034\n",
            "Epoch 140 Loss 5.003007\n",
            "Time taken for 1 epoch 64.22850918769836 sec\n",
            "\n",
            "Epoch 141 Batch 0 Loss 0.1265\n",
            "Epoch 141 Batch 0 Accuracy 0.0035\n",
            "Epoch 141 Batch 50 Loss 0.1273\n",
            "Epoch 141 Batch 50 Accuracy 0.0035\n",
            "Epoch 141 Batch 100 Loss 0.1270\n",
            "Epoch 141 Batch 100 Accuracy 0.0034\n",
            "Epoch 141 Batch 150 Loss 0.1262\n",
            "Epoch 141 Batch 150 Accuracy 0.0036\n",
            "Epoch 141 Batch 200 Loss 0.1270\n",
            "Epoch 141 Batch 200 Accuracy 0.0038\n",
            "Epoch 141 Loss 5.005224\n",
            "Time taken for 1 epoch 64.31460547447205 sec\n",
            "\n",
            "Epoch 142 Batch 0 Loss 0.1291\n",
            "Epoch 142 Batch 0 Accuracy 0.0035\n",
            "Epoch 142 Batch 50 Loss 0.1280\n",
            "Epoch 142 Batch 50 Accuracy 0.0035\n",
            "Epoch 142 Batch 100 Loss 0.1272\n",
            "Epoch 142 Batch 100 Accuracy 0.0035\n",
            "Epoch 142 Batch 150 Loss 0.1270\n",
            "Epoch 142 Batch 150 Accuracy 0.0036\n",
            "Epoch 142 Batch 200 Loss 0.1265\n",
            "Epoch 142 Batch 200 Accuracy 0.0035\n",
            "Epoch 142 Loss 5.005013\n",
            "Time taken for 1 epoch 64.53027415275574 sec\n",
            "\n",
            "Epoch 143 Batch 0 Loss 0.1301\n",
            "Epoch 143 Batch 0 Accuracy 0.0034\n",
            "Epoch 143 Batch 50 Loss 0.1272\n",
            "Epoch 143 Batch 50 Accuracy 0.0035\n",
            "Epoch 143 Batch 100 Loss 0.1278\n",
            "Epoch 143 Batch 100 Accuracy 0.0035\n",
            "Epoch 143 Batch 150 Loss 0.1259\n",
            "Epoch 143 Batch 150 Accuracy 0.0035\n",
            "Epoch 143 Batch 200 Loss 0.1278\n",
            "Epoch 143 Batch 200 Accuracy 0.0033\n",
            "Epoch 143 Loss 5.005013\n",
            "Time taken for 1 epoch 64.82649517059326 sec\n",
            "\n",
            "Epoch 144 Batch 0 Loss 0.1273\n",
            "Epoch 144 Batch 0 Accuracy 0.0036\n",
            "Epoch 144 Batch 50 Loss 0.1263\n",
            "Epoch 144 Batch 50 Accuracy 0.0037\n",
            "Epoch 144 Batch 100 Loss 0.1272\n",
            "Epoch 144 Batch 100 Accuracy 0.0034\n",
            "Epoch 144 Batch 150 Loss 0.1294\n",
            "Epoch 144 Batch 150 Accuracy 0.0033\n",
            "Epoch 144 Batch 200 Loss 0.1310\n",
            "Epoch 144 Batch 200 Accuracy 0.0032\n",
            "Epoch 144 Loss 5.004524\n",
            "Time taken for 1 epoch 63.96016550064087 sec\n",
            "\n",
            "Epoch 145 Batch 0 Loss 0.1263\n",
            "Epoch 145 Batch 0 Accuracy 0.0036\n",
            "Epoch 145 Batch 50 Loss 0.1288\n",
            "Epoch 145 Batch 50 Accuracy 0.0034\n",
            "Epoch 145 Batch 100 Loss 0.1277\n",
            "Epoch 145 Batch 100 Accuracy 0.0037\n",
            "Epoch 145 Batch 150 Loss 0.1271\n",
            "Epoch 145 Batch 150 Accuracy 0.0034\n",
            "Epoch 145 Batch 200 Loss 0.1277\n",
            "Epoch 145 Batch 200 Accuracy 0.0035\n",
            "Epoch 145 Loss 5.005480\n",
            "Time taken for 1 epoch 64.08677530288696 sec\n",
            "\n",
            "Epoch 146 Batch 0 Loss 0.1276\n",
            "Epoch 146 Batch 0 Accuracy 0.0036\n",
            "Epoch 146 Batch 50 Loss 0.1277\n",
            "Epoch 146 Batch 50 Accuracy 0.0036\n",
            "Epoch 146 Batch 100 Loss 0.1282\n",
            "Epoch 146 Batch 100 Accuracy 0.0035\n",
            "Epoch 146 Batch 150 Loss 0.1259\n",
            "Epoch 146 Batch 150 Accuracy 0.0036\n",
            "Epoch 146 Batch 200 Loss 0.1268\n",
            "Epoch 146 Batch 200 Accuracy 0.0032\n",
            "Epoch 146 Loss 5.004343\n",
            "Time taken for 1 epoch 64.44111108779907 sec\n",
            "\n",
            "Epoch 147 Batch 0 Loss 0.1292\n",
            "Epoch 147 Batch 0 Accuracy 0.0034\n",
            "Epoch 147 Batch 50 Loss 0.1279\n",
            "Epoch 147 Batch 50 Accuracy 0.0034\n",
            "Epoch 147 Batch 100 Loss 0.1268\n",
            "Epoch 147 Batch 100 Accuracy 0.0035\n",
            "Epoch 147 Batch 150 Loss 0.1260\n",
            "Epoch 147 Batch 150 Accuracy 0.0035\n",
            "Epoch 147 Batch 200 Loss 0.1280\n",
            "Epoch 147 Batch 200 Accuracy 0.0033\n",
            "Epoch 147 Loss 5.003002\n",
            "Time taken for 1 epoch 64.46733546257019 sec\n",
            "\n",
            "Epoch 148 Batch 0 Loss 0.1289\n",
            "Epoch 148 Batch 0 Accuracy 0.0034\n",
            "Epoch 148 Batch 50 Loss 0.1291\n",
            "Epoch 148 Batch 50 Accuracy 0.0034\n",
            "Epoch 148 Batch 100 Loss 0.1285\n",
            "Epoch 148 Batch 100 Accuracy 0.0034\n",
            "Epoch 148 Batch 150 Loss 0.1264\n",
            "Epoch 148 Batch 150 Accuracy 0.0037\n",
            "Epoch 148 Batch 200 Loss 0.1264\n",
            "Epoch 148 Batch 200 Accuracy 0.0035\n",
            "Epoch 148 Loss 5.006259\n",
            "Time taken for 1 epoch 64.28191924095154 sec\n",
            "\n",
            "Epoch 149 Batch 0 Loss 0.1303\n",
            "Epoch 149 Batch 0 Accuracy 0.0034\n",
            "Epoch 149 Batch 50 Loss 0.1270\n",
            "Epoch 149 Batch 50 Accuracy 0.0034\n",
            "Epoch 149 Batch 100 Loss 0.1287\n",
            "Epoch 149 Batch 100 Accuracy 0.0033\n",
            "Epoch 149 Batch 150 Loss 0.1278\n",
            "Epoch 149 Batch 150 Accuracy 0.0034\n",
            "Epoch 149 Batch 200 Loss 0.1299\n",
            "Epoch 149 Batch 200 Accuracy 0.0033\n",
            "Epoch 149 Loss 5.004244\n",
            "Time taken for 1 epoch 64.27339935302734 sec\n",
            "\n",
            "Epoch 150 Batch 0 Loss 0.1275\n",
            "Epoch 150 Batch 0 Accuracy 0.0036\n",
            "Epoch 150 Batch 50 Loss 0.1266\n",
            "Epoch 150 Batch 50 Accuracy 0.0036\n",
            "Epoch 150 Batch 100 Loss 0.1294\n",
            "Epoch 150 Batch 100 Accuracy 0.0035\n",
            "Epoch 150 Batch 150 Loss 0.1253\n",
            "Epoch 150 Batch 150 Accuracy 0.0035\n",
            "Epoch 150 Batch 200 Loss 0.1282\n",
            "Epoch 150 Batch 200 Accuracy 0.0035\n",
            "Epoch 150 Loss 5.003333\n",
            "Time taken for 1 epoch 65.02229452133179 sec\n",
            "\n",
            "Epoch 151 Batch 0 Loss 0.1296\n",
            "Epoch 151 Batch 0 Accuracy 0.0032\n",
            "Epoch 151 Batch 50 Loss 0.1271\n",
            "Epoch 151 Batch 50 Accuracy 0.0035\n",
            "Epoch 151 Batch 100 Loss 0.1276\n",
            "Epoch 151 Batch 100 Accuracy 0.0035\n",
            "Epoch 151 Batch 150 Loss 0.1301\n",
            "Epoch 151 Batch 150 Accuracy 0.0032\n",
            "Epoch 151 Batch 200 Loss 0.1263\n",
            "Epoch 151 Batch 200 Accuracy 0.0036\n",
            "Epoch 151 Loss 5.003386\n",
            "Time taken for 1 epoch 64.53427290916443 sec\n",
            "\n",
            "Epoch 152 Batch 0 Loss 0.1291\n",
            "Epoch 152 Batch 0 Accuracy 0.0034\n",
            "Epoch 152 Batch 50 Loss 0.1266\n",
            "Epoch 152 Batch 50 Accuracy 0.0034\n",
            "Epoch 152 Batch 100 Loss 0.1291\n",
            "Epoch 152 Batch 100 Accuracy 0.0033\n",
            "Epoch 152 Batch 150 Loss 0.1280\n",
            "Epoch 152 Batch 150 Accuracy 0.0035\n",
            "Epoch 152 Batch 200 Loss 0.1248\n",
            "Epoch 152 Batch 200 Accuracy 0.0034\n",
            "Epoch 152 Loss 5.003801\n",
            "Time taken for 1 epoch 64.75107884407043 sec\n",
            "\n",
            "Epoch 153 Batch 0 Loss 0.1292\n",
            "Epoch 153 Batch 0 Accuracy 0.0034\n",
            "Epoch 153 Batch 50 Loss 0.1278\n",
            "Epoch 153 Batch 50 Accuracy 0.0035\n",
            "Epoch 153 Batch 100 Loss 0.1261\n",
            "Epoch 153 Batch 100 Accuracy 0.0034\n",
            "Epoch 153 Batch 150 Loss 0.1264\n",
            "Epoch 153 Batch 150 Accuracy 0.0034\n",
            "Epoch 153 Batch 200 Loss 0.1280\n",
            "Epoch 153 Batch 200 Accuracy 0.0032\n",
            "Epoch 153 Loss 5.004091\n",
            "Time taken for 1 epoch 63.85713839530945 sec\n",
            "\n",
            "Epoch 154 Batch 0 Loss 0.1273\n",
            "Epoch 154 Batch 0 Accuracy 0.0034\n",
            "Epoch 154 Batch 50 Loss 0.1258\n",
            "Epoch 154 Batch 50 Accuracy 0.0035\n",
            "Epoch 154 Batch 100 Loss 0.1271\n",
            "Epoch 154 Batch 100 Accuracy 0.0035\n",
            "Epoch 154 Batch 150 Loss 0.1270\n",
            "Epoch 154 Batch 150 Accuracy 0.0032\n",
            "Epoch 154 Batch 200 Loss 0.1276\n",
            "Epoch 154 Batch 200 Accuracy 0.0033\n",
            "Epoch 154 Loss 5.003944\n",
            "Time taken for 1 epoch 63.72718548774719 sec\n",
            "\n",
            "Epoch 155 Batch 0 Loss 0.1269\n",
            "Epoch 155 Batch 0 Accuracy 0.0033\n",
            "Epoch 155 Batch 50 Loss 0.1273\n",
            "Epoch 155 Batch 50 Accuracy 0.0036\n",
            "Epoch 155 Batch 100 Loss 0.1293\n",
            "Epoch 155 Batch 100 Accuracy 0.0034\n",
            "Epoch 155 Batch 150 Loss 0.1252\n",
            "Epoch 155 Batch 150 Accuracy 0.0038\n",
            "Epoch 155 Batch 200 Loss 0.1255\n",
            "Epoch 155 Batch 200 Accuracy 0.0033\n",
            "Epoch 155 Loss 5.004632\n",
            "Time taken for 1 epoch 64.08466243743896 sec\n",
            "\n",
            "Epoch 156 Batch 0 Loss 0.1274\n",
            "Epoch 156 Batch 0 Accuracy 0.0035\n",
            "Epoch 156 Batch 50 Loss 0.1287\n",
            "Epoch 156 Batch 50 Accuracy 0.0033\n",
            "Epoch 156 Batch 100 Loss 0.1268\n",
            "Epoch 156 Batch 100 Accuracy 0.0036\n",
            "Epoch 156 Batch 150 Loss 0.1257\n",
            "Epoch 156 Batch 150 Accuracy 0.0034\n",
            "Epoch 156 Batch 200 Loss 0.1262\n",
            "Epoch 156 Batch 200 Accuracy 0.0035\n",
            "Epoch 156 Loss 5.004196\n",
            "Time taken for 1 epoch 64.31883788108826 sec\n",
            "\n",
            "Epoch 157 Batch 0 Loss 0.1283\n",
            "Epoch 157 Batch 0 Accuracy 0.0034\n",
            "Epoch 157 Batch 50 Loss 0.1278\n",
            "Epoch 157 Batch 50 Accuracy 0.0035\n",
            "Epoch 157 Batch 100 Loss 0.1276\n",
            "Epoch 157 Batch 100 Accuracy 0.0035\n",
            "Epoch 157 Batch 150 Loss 0.1284\n",
            "Epoch 157 Batch 150 Accuracy 0.0035\n",
            "Epoch 157 Batch 200 Loss 0.1282\n",
            "Epoch 157 Batch 200 Accuracy 0.0032\n",
            "Epoch 157 Loss 5.005199\n",
            "Time taken for 1 epoch 64.73155450820923 sec\n",
            "\n",
            "Epoch 158 Batch 0 Loss 0.1290\n",
            "Epoch 158 Batch 0 Accuracy 0.0033\n",
            "Epoch 158 Batch 50 Loss 0.1278\n",
            "Epoch 158 Batch 50 Accuracy 0.0035\n",
            "Epoch 158 Batch 100 Loss 0.1264\n",
            "Epoch 158 Batch 100 Accuracy 0.0036\n",
            "Epoch 158 Batch 150 Loss 0.1285\n",
            "Epoch 158 Batch 150 Accuracy 0.0035\n",
            "Epoch 158 Batch 200 Loss 0.1292\n",
            "Epoch 158 Batch 200 Accuracy 0.0036\n",
            "Epoch 158 Loss 5.004337\n",
            "Time taken for 1 epoch 64.12143087387085 sec\n",
            "\n",
            "Epoch 159 Batch 0 Loss 0.1287\n",
            "Epoch 159 Batch 0 Accuracy 0.0033\n",
            "Epoch 159 Batch 50 Loss 0.1284\n",
            "Epoch 159 Batch 50 Accuracy 0.0036\n",
            "Epoch 159 Batch 100 Loss 0.1277\n",
            "Epoch 159 Batch 100 Accuracy 0.0039\n",
            "Epoch 159 Batch 150 Loss 0.1282\n",
            "Epoch 159 Batch 150 Accuracy 0.0035\n",
            "Epoch 159 Batch 200 Loss 0.1286\n",
            "Epoch 159 Batch 200 Accuracy 0.0031\n",
            "Epoch 159 Loss 5.002769\n",
            "Time taken for 1 epoch 64.06040930747986 sec\n",
            "\n",
            "Epoch 160 Batch 0 Loss 0.1267\n",
            "Epoch 160 Batch 0 Accuracy 0.0036\n",
            "Epoch 160 Batch 50 Loss 0.1297\n",
            "Epoch 160 Batch 50 Accuracy 0.0031\n",
            "Epoch 160 Batch 100 Loss 0.1266\n",
            "Epoch 160 Batch 100 Accuracy 0.0036\n",
            "Epoch 160 Batch 150 Loss 0.1302\n",
            "Epoch 160 Batch 150 Accuracy 0.0032\n",
            "Epoch 160 Batch 200 Loss 0.1264\n",
            "Epoch 160 Batch 200 Accuracy 0.0033\n",
            "Epoch 160 Loss 5.003516\n",
            "Time taken for 1 epoch 63.8352165222168 sec\n",
            "\n",
            "Epoch 161 Batch 0 Loss 0.1289\n",
            "Epoch 161 Batch 0 Accuracy 0.0034\n",
            "Epoch 161 Batch 50 Loss 0.1266\n",
            "Epoch 161 Batch 50 Accuracy 0.0035\n",
            "Epoch 161 Batch 100 Loss 0.1278\n",
            "Epoch 161 Batch 100 Accuracy 0.0036\n",
            "Epoch 161 Batch 150 Loss 0.1258\n",
            "Epoch 161 Batch 150 Accuracy 0.0036\n",
            "Epoch 161 Batch 200 Loss 0.1271\n",
            "Epoch 161 Batch 200 Accuracy 0.0034\n",
            "Epoch 161 Loss 5.003732\n",
            "Time taken for 1 epoch 64.43724417686462 sec\n",
            "\n",
            "Epoch 162 Batch 0 Loss 0.1297\n",
            "Epoch 162 Batch 0 Accuracy 0.0034\n",
            "Epoch 162 Batch 50 Loss 0.1255\n",
            "Epoch 162 Batch 50 Accuracy 0.0039\n",
            "Epoch 162 Batch 100 Loss 0.1266\n",
            "Epoch 162 Batch 100 Accuracy 0.0037\n",
            "Epoch 162 Batch 150 Loss 0.1272\n",
            "Epoch 162 Batch 150 Accuracy 0.0037\n",
            "Epoch 162 Batch 200 Loss 0.1267\n",
            "Epoch 162 Batch 200 Accuracy 0.0033\n",
            "Epoch 162 Loss 5.003099\n",
            "Time taken for 1 epoch 64.5754747390747 sec\n",
            "\n",
            "Epoch 163 Batch 0 Loss 0.1283\n",
            "Epoch 163 Batch 0 Accuracy 0.0034\n",
            "Epoch 163 Batch 50 Loss 0.1273\n",
            "Epoch 163 Batch 50 Accuracy 0.0037\n",
            "Epoch 163 Batch 100 Loss 0.1289\n",
            "Epoch 163 Batch 100 Accuracy 0.0033\n",
            "Epoch 163 Batch 150 Loss 0.1283\n",
            "Epoch 163 Batch 150 Accuracy 0.0036\n",
            "Epoch 163 Batch 200 Loss 0.1258\n",
            "Epoch 163 Batch 200 Accuracy 0.0035\n",
            "Epoch 163 Loss 5.005161\n",
            "Time taken for 1 epoch 63.855167388916016 sec\n",
            "\n",
            "Epoch 164 Batch 0 Loss 0.1262\n",
            "Epoch 164 Batch 0 Accuracy 0.0034\n",
            "Epoch 164 Batch 50 Loss 0.1281\n",
            "Epoch 164 Batch 50 Accuracy 0.0035\n",
            "Epoch 164 Batch 100 Loss 0.1258\n",
            "Epoch 164 Batch 100 Accuracy 0.0033\n",
            "Epoch 164 Batch 150 Loss 0.1265\n",
            "Epoch 164 Batch 150 Accuracy 0.0034\n",
            "Epoch 164 Batch 200 Loss 0.1264\n",
            "Epoch 164 Batch 200 Accuracy 0.0032\n",
            "Epoch 164 Loss 5.003876\n",
            "Time taken for 1 epoch 63.747047424316406 sec\n",
            "\n",
            "Epoch 165 Batch 0 Loss 0.1276\n",
            "Epoch 165 Batch 0 Accuracy 0.0038\n",
            "Epoch 165 Batch 50 Loss 0.1273\n",
            "Epoch 165 Batch 50 Accuracy 0.0036\n",
            "Epoch 165 Batch 100 Loss 0.1283\n",
            "Epoch 165 Batch 100 Accuracy 0.0036\n",
            "Epoch 165 Batch 150 Loss 0.1258\n",
            "Epoch 165 Batch 150 Accuracy 0.0037\n",
            "Epoch 165 Batch 200 Loss 0.1285\n",
            "Epoch 165 Batch 200 Accuracy 0.0035\n",
            "Epoch 165 Loss 5.004564\n",
            "Time taken for 1 epoch 63.84552836418152 sec\n",
            "\n",
            "Epoch 166 Batch 0 Loss 0.1288\n",
            "Epoch 166 Batch 0 Accuracy 0.0033\n",
            "Epoch 166 Batch 50 Loss 0.1277\n",
            "Epoch 166 Batch 50 Accuracy 0.0034\n",
            "Epoch 166 Batch 100 Loss 0.1275\n",
            "Epoch 166 Batch 100 Accuracy 0.0035\n",
            "Epoch 166 Batch 150 Loss 0.1275\n",
            "Epoch 166 Batch 150 Accuracy 0.0035\n",
            "Epoch 166 Batch 200 Loss 0.1275\n",
            "Epoch 166 Batch 200 Accuracy 0.0037\n",
            "Epoch 166 Loss 5.003273\n",
            "Time taken for 1 epoch 63.998764991760254 sec\n",
            "\n",
            "Epoch 167 Batch 0 Loss 0.1282\n",
            "Epoch 167 Batch 0 Accuracy 0.0031\n",
            "Epoch 167 Batch 50 Loss 0.1298\n",
            "Epoch 167 Batch 50 Accuracy 0.0033\n",
            "Epoch 167 Batch 100 Loss 0.1264\n",
            "Epoch 167 Batch 100 Accuracy 0.0038\n",
            "Epoch 167 Batch 150 Loss 0.1261\n",
            "Epoch 167 Batch 150 Accuracy 0.0035\n",
            "Epoch 167 Batch 200 Loss 0.1298\n",
            "Epoch 167 Batch 200 Accuracy 0.0032\n",
            "Epoch 167 Loss 5.001939\n",
            "Time taken for 1 epoch 64.49815487861633 sec\n",
            "\n",
            "Epoch 168 Batch 0 Loss 0.1271\n",
            "Epoch 168 Batch 0 Accuracy 0.0036\n",
            "Epoch 168 Batch 50 Loss 0.1276\n",
            "Epoch 168 Batch 50 Accuracy 0.0035\n",
            "Epoch 168 Batch 100 Loss 0.1272\n",
            "Epoch 168 Batch 100 Accuracy 0.0037\n",
            "Epoch 168 Batch 150 Loss 0.1273\n",
            "Epoch 168 Batch 150 Accuracy 0.0036\n",
            "Epoch 168 Batch 200 Loss 0.1284\n",
            "Epoch 168 Batch 200 Accuracy 0.0035\n",
            "Epoch 168 Loss 5.003611\n",
            "Time taken for 1 epoch 64.15111804008484 sec\n",
            "\n",
            "Epoch 169 Batch 0 Loss 0.1305\n",
            "Epoch 169 Batch 0 Accuracy 0.0033\n",
            "Epoch 169 Batch 50 Loss 0.1266\n",
            "Epoch 169 Batch 50 Accuracy 0.0035\n",
            "Epoch 169 Batch 100 Loss 0.1250\n",
            "Epoch 169 Batch 100 Accuracy 0.0036\n",
            "Epoch 169 Batch 150 Loss 0.1242\n",
            "Epoch 169 Batch 150 Accuracy 0.0037\n",
            "Epoch 169 Batch 200 Loss 0.1286\n",
            "Epoch 169 Batch 200 Accuracy 0.0034\n",
            "Epoch 169 Loss 5.004207\n",
            "Time taken for 1 epoch 65.69890522956848 sec\n",
            "\n",
            "Epoch 170 Batch 0 Loss 0.1278\n",
            "Epoch 170 Batch 0 Accuracy 0.0035\n",
            "Epoch 170 Batch 50 Loss 0.1279\n",
            "Epoch 170 Batch 50 Accuracy 0.0032\n",
            "Epoch 170 Batch 100 Loss 0.1282\n",
            "Epoch 170 Batch 100 Accuracy 0.0034\n",
            "Epoch 170 Batch 150 Loss 0.1280\n",
            "Epoch 170 Batch 150 Accuracy 0.0033\n",
            "Epoch 170 Batch 200 Loss 0.1273\n",
            "Epoch 170 Batch 200 Accuracy 0.0034\n",
            "Epoch 170 Loss 5.005144\n",
            "Time taken for 1 epoch 67.27627110481262 sec\n",
            "\n",
            "Epoch 171 Batch 0 Loss 0.1274\n",
            "Epoch 171 Batch 0 Accuracy 0.0035\n",
            "Epoch 171 Batch 50 Loss 0.1287\n",
            "Epoch 171 Batch 50 Accuracy 0.0031\n",
            "Epoch 171 Batch 100 Loss 0.1263\n",
            "Epoch 171 Batch 100 Accuracy 0.0036\n",
            "Epoch 171 Batch 150 Loss 0.1284\n",
            "Epoch 171 Batch 150 Accuracy 0.0034\n",
            "Epoch 171 Batch 200 Loss 0.1295\n",
            "Epoch 171 Batch 200 Accuracy 0.0032\n",
            "Epoch 171 Loss 5.004683\n",
            "Time taken for 1 epoch 68.82986307144165 sec\n",
            "\n",
            "Epoch 172 Batch 0 Loss 0.1278\n",
            "Epoch 172 Batch 0 Accuracy 0.0035\n",
            "Epoch 172 Batch 50 Loss 0.1275\n",
            "Epoch 172 Batch 50 Accuracy 0.0033\n",
            "Epoch 172 Batch 100 Loss 0.1257\n",
            "Epoch 172 Batch 100 Accuracy 0.0034\n",
            "Epoch 172 Batch 150 Loss 0.1269\n",
            "Epoch 172 Batch 150 Accuracy 0.0034\n",
            "Epoch 172 Batch 200 Loss 0.1270\n",
            "Epoch 172 Batch 200 Accuracy 0.0035\n",
            "Epoch 172 Loss 5.005136\n",
            "Time taken for 1 epoch 69.3885862827301 sec\n",
            "\n",
            "Epoch 173 Batch 0 Loss 0.1284\n",
            "Epoch 173 Batch 0 Accuracy 0.0033\n",
            "Epoch 173 Batch 50 Loss 0.1259\n",
            "Epoch 173 Batch 50 Accuracy 0.0033\n",
            "Epoch 173 Batch 100 Loss 0.1281\n",
            "Epoch 173 Batch 100 Accuracy 0.0032\n",
            "Epoch 173 Batch 150 Loss 0.1247\n",
            "Epoch 173 Batch 150 Accuracy 0.0037\n",
            "Epoch 173 Batch 200 Loss 0.1287\n",
            "Epoch 173 Batch 200 Accuracy 0.0033\n",
            "Epoch 173 Loss 5.002524\n",
            "Time taken for 1 epoch 69.36991620063782 sec\n",
            "\n",
            "Epoch 174 Batch 0 Loss 0.1294\n",
            "Epoch 174 Batch 0 Accuracy 0.0035\n",
            "Epoch 174 Batch 50 Loss 0.1288\n",
            "Epoch 174 Batch 50 Accuracy 0.0034\n",
            "Epoch 174 Batch 100 Loss 0.1304\n",
            "Epoch 174 Batch 100 Accuracy 0.0033\n",
            "Epoch 174 Batch 150 Loss 0.1266\n",
            "Epoch 174 Batch 150 Accuracy 0.0037\n",
            "Epoch 174 Batch 200 Loss 0.1284\n",
            "Epoch 174 Batch 200 Accuracy 0.0030\n",
            "Epoch 174 Loss 5.002789\n",
            "Time taken for 1 epoch 69.83360314369202 sec\n",
            "\n",
            "Epoch 175 Batch 0 Loss 0.1271\n",
            "Epoch 175 Batch 0 Accuracy 0.0035\n",
            "Epoch 175 Batch 50 Loss 0.1272\n",
            "Epoch 175 Batch 50 Accuracy 0.0034\n",
            "Epoch 175 Batch 100 Loss 0.1287\n",
            "Epoch 175 Batch 100 Accuracy 0.0037\n",
            "Epoch 175 Batch 150 Loss 0.1252\n",
            "Epoch 175 Batch 150 Accuracy 0.0035\n",
            "Epoch 175 Batch 200 Loss 0.1282\n",
            "Epoch 175 Batch 200 Accuracy 0.0035\n",
            "Epoch 175 Loss 5.004273\n",
            "Time taken for 1 epoch 69.78998494148254 sec\n",
            "\n",
            "Epoch 176 Batch 0 Loss 0.1289\n",
            "Epoch 176 Batch 0 Accuracy 0.0034\n",
            "Epoch 176 Batch 50 Loss 0.1270\n",
            "Epoch 176 Batch 50 Accuracy 0.0035\n",
            "Epoch 176 Batch 100 Loss 0.1274\n",
            "Epoch 176 Batch 100 Accuracy 0.0035\n",
            "Epoch 176 Batch 150 Loss 0.1257\n",
            "Epoch 176 Batch 150 Accuracy 0.0036\n",
            "Epoch 176 Batch 200 Loss 0.1292\n",
            "Epoch 176 Batch 200 Accuracy 0.0031\n",
            "Epoch 176 Loss 5.002522\n",
            "Time taken for 1 epoch 70.96641492843628 sec\n",
            "\n",
            "Epoch 177 Batch 0 Loss 0.1291\n",
            "Epoch 177 Batch 0 Accuracy 0.0035\n",
            "Epoch 177 Batch 50 Loss 0.1267\n",
            "Epoch 177 Batch 50 Accuracy 0.0036\n",
            "Epoch 177 Batch 100 Loss 0.1306\n",
            "Epoch 177 Batch 100 Accuracy 0.0034\n",
            "Epoch 177 Batch 150 Loss 0.1268\n",
            "Epoch 177 Batch 150 Accuracy 0.0034\n",
            "Epoch 177 Batch 200 Loss 0.1276\n",
            "Epoch 177 Batch 200 Accuracy 0.0035\n",
            "Epoch 177 Loss 5.003809\n",
            "Time taken for 1 epoch 70.28945755958557 sec\n",
            "\n",
            "Epoch 178 Batch 0 Loss 0.1265\n",
            "Epoch 178 Batch 0 Accuracy 0.0036\n",
            "Epoch 178 Batch 50 Loss 0.1278\n",
            "Epoch 178 Batch 50 Accuracy 0.0035\n",
            "Epoch 178 Batch 100 Loss 0.1294\n",
            "Epoch 178 Batch 100 Accuracy 0.0035\n",
            "Epoch 178 Batch 150 Loss 0.1264\n",
            "Epoch 178 Batch 150 Accuracy 0.0035\n",
            "Epoch 178 Batch 200 Loss 0.1267\n",
            "Epoch 178 Batch 200 Accuracy 0.0034\n",
            "Epoch 178 Loss 5.002834\n",
            "Time taken for 1 epoch 70.07027745246887 sec\n",
            "\n",
            "Epoch 179 Batch 0 Loss 0.1276\n",
            "Epoch 179 Batch 0 Accuracy 0.0037\n",
            "Epoch 179 Batch 50 Loss 0.1266\n",
            "Epoch 179 Batch 50 Accuracy 0.0034\n",
            "Epoch 179 Batch 100 Loss 0.1291\n",
            "Epoch 179 Batch 100 Accuracy 0.0034\n",
            "Epoch 179 Batch 150 Loss 0.1266\n",
            "Epoch 179 Batch 150 Accuracy 0.0033\n",
            "Epoch 179 Batch 200 Loss 0.1297\n",
            "Epoch 179 Batch 200 Accuracy 0.0032\n",
            "Epoch 179 Loss 5.002030\n",
            "Time taken for 1 epoch 70.13287901878357 sec\n",
            "\n",
            "Epoch 180 Batch 0 Loss 0.1292\n",
            "Epoch 180 Batch 0 Accuracy 0.0035\n",
            "Epoch 180 Batch 50 Loss 0.1259\n",
            "Epoch 180 Batch 50 Accuracy 0.0039\n",
            "Epoch 180 Batch 100 Loss 0.1274\n",
            "Epoch 180 Batch 100 Accuracy 0.0034\n",
            "Epoch 180 Batch 150 Loss 0.1274\n",
            "Epoch 180 Batch 150 Accuracy 0.0037\n",
            "Epoch 180 Batch 200 Loss 0.1271\n",
            "Epoch 180 Batch 200 Accuracy 0.0035\n",
            "Epoch 180 Loss 5.003445\n",
            "Time taken for 1 epoch 70.83409261703491 sec\n",
            "\n",
            "Epoch 181 Batch 0 Loss 0.1281\n",
            "Epoch 181 Batch 0 Accuracy 0.0034\n",
            "Epoch 181 Batch 50 Loss 0.1294\n",
            "Epoch 181 Batch 50 Accuracy 0.0032\n",
            "Epoch 181 Batch 100 Loss 0.1293\n",
            "Epoch 181 Batch 100 Accuracy 0.0034\n",
            "Epoch 181 Batch 150 Loss 0.1262\n",
            "Epoch 181 Batch 150 Accuracy 0.0037\n",
            "Epoch 181 Batch 200 Loss 0.1277\n",
            "Epoch 181 Batch 200 Accuracy 0.0033\n",
            "Epoch 181 Loss 5.004462\n",
            "Time taken for 1 epoch 70.56048464775085 sec\n",
            "\n",
            "Epoch 182 Batch 0 Loss 0.1287\n",
            "Epoch 182 Batch 0 Accuracy 0.0032\n",
            "Epoch 182 Batch 50 Loss 0.1281\n",
            "Epoch 182 Batch 50 Accuracy 0.0034\n",
            "Epoch 182 Batch 100 Loss 0.1253\n",
            "Epoch 182 Batch 100 Accuracy 0.0036\n",
            "Epoch 182 Batch 150 Loss 0.1275\n",
            "Epoch 182 Batch 150 Accuracy 0.0035\n",
            "Epoch 182 Batch 200 Loss 0.1271\n",
            "Epoch 182 Batch 200 Accuracy 0.0034\n",
            "Epoch 182 Loss 5.004278\n",
            "Time taken for 1 epoch 70.23483276367188 sec\n",
            "\n",
            "Epoch 183 Batch 0 Loss 0.1291\n",
            "Epoch 183 Batch 0 Accuracy 0.0034\n",
            "Epoch 183 Batch 50 Loss 0.1255\n",
            "Epoch 183 Batch 50 Accuracy 0.0038\n",
            "Epoch 183 Batch 100 Loss 0.1280\n",
            "Epoch 183 Batch 100 Accuracy 0.0036\n",
            "Epoch 183 Batch 150 Loss 0.1282\n",
            "Epoch 183 Batch 150 Accuracy 0.0034\n",
            "Epoch 183 Batch 200 Loss 0.1296\n",
            "Epoch 183 Batch 200 Accuracy 0.0030\n",
            "Epoch 183 Loss 5.005393\n",
            "Time taken for 1 epoch 68.95315217971802 sec\n",
            "\n",
            "Epoch 184 Batch 0 Loss 0.1272\n",
            "Epoch 184 Batch 0 Accuracy 0.0034\n",
            "Epoch 184 Batch 50 Loss 0.1285\n",
            "Epoch 184 Batch 50 Accuracy 0.0035\n",
            "Epoch 184 Batch 100 Loss 0.1289\n",
            "Epoch 184 Batch 100 Accuracy 0.0033\n",
            "Epoch 184 Batch 150 Loss 0.1273\n",
            "Epoch 184 Batch 150 Accuracy 0.0034\n",
            "Epoch 184 Batch 200 Loss 0.1286\n",
            "Epoch 184 Batch 200 Accuracy 0.0035\n",
            "Epoch 184 Loss 5.005357\n",
            "Time taken for 1 epoch 69.3217260837555 sec\n",
            "\n",
            "Epoch 185 Batch 0 Loss 0.1287\n",
            "Epoch 185 Batch 0 Accuracy 0.0033\n",
            "Epoch 185 Batch 50 Loss 0.1287\n",
            "Epoch 185 Batch 50 Accuracy 0.0033\n",
            "Epoch 185 Batch 100 Loss 0.1274\n",
            "Epoch 185 Batch 100 Accuracy 0.0035\n",
            "Epoch 185 Batch 150 Loss 0.1280\n",
            "Epoch 185 Batch 150 Accuracy 0.0037\n",
            "Epoch 185 Batch 200 Loss 0.1265\n",
            "Epoch 185 Batch 200 Accuracy 0.0035\n",
            "Epoch 185 Loss 5.002090\n",
            "Time taken for 1 epoch 70.23129892349243 sec\n",
            "\n",
            "Epoch 186 Batch 0 Loss 0.1269\n",
            "Epoch 186 Batch 0 Accuracy 0.0034\n",
            "Epoch 186 Batch 50 Loss 0.1263\n",
            "Epoch 186 Batch 50 Accuracy 0.0033\n",
            "Epoch 186 Batch 100 Loss 0.1299\n",
            "Epoch 186 Batch 100 Accuracy 0.0032\n",
            "Epoch 186 Batch 150 Loss 0.1278\n",
            "Epoch 186 Batch 150 Accuracy 0.0034\n",
            "Epoch 186 Batch 200 Loss 0.1282\n",
            "Epoch 186 Batch 200 Accuracy 0.0035\n",
            "Epoch 186 Loss 5.003880\n",
            "Time taken for 1 epoch 70.23446345329285 sec\n",
            "\n",
            "Epoch 187 Batch 0 Loss 0.1284\n",
            "Epoch 187 Batch 0 Accuracy 0.0034\n",
            "Epoch 187 Batch 50 Loss 0.1274\n",
            "Epoch 187 Batch 50 Accuracy 0.0037\n",
            "Epoch 187 Batch 100 Loss 0.1269\n",
            "Epoch 187 Batch 100 Accuracy 0.0037\n",
            "Epoch 187 Batch 150 Loss 0.1275\n",
            "Epoch 187 Batch 150 Accuracy 0.0033\n",
            "Epoch 187 Batch 200 Loss 0.1280\n",
            "Epoch 187 Batch 200 Accuracy 0.0033\n",
            "Epoch 187 Loss 5.002811\n",
            "Time taken for 1 epoch 70.2183358669281 sec\n",
            "\n",
            "Epoch 188 Batch 0 Loss 0.1270\n",
            "Epoch 188 Batch 0 Accuracy 0.0036\n",
            "Epoch 188 Batch 50 Loss 0.1275\n",
            "Epoch 188 Batch 50 Accuracy 0.0037\n",
            "Epoch 188 Batch 100 Loss 0.1303\n",
            "Epoch 188 Batch 100 Accuracy 0.0035\n",
            "Epoch 188 Batch 150 Loss 0.1267\n",
            "Epoch 188 Batch 150 Accuracy 0.0032\n",
            "Epoch 188 Batch 200 Loss 0.1267\n",
            "Epoch 188 Batch 200 Accuracy 0.0034\n",
            "Epoch 188 Loss 5.003600\n",
            "Time taken for 1 epoch 70.12367725372314 sec\n",
            "\n",
            "Epoch 189 Batch 0 Loss 0.1278\n",
            "Epoch 189 Batch 0 Accuracy 0.0035\n",
            "Epoch 189 Batch 50 Loss 0.1275\n",
            "Epoch 189 Batch 50 Accuracy 0.0036\n",
            "Epoch 189 Batch 100 Loss 0.1274\n",
            "Epoch 189 Batch 100 Accuracy 0.0035\n",
            "Epoch 189 Batch 150 Loss 0.1275\n",
            "Epoch 189 Batch 150 Accuracy 0.0036\n",
            "Epoch 189 Batch 200 Loss 0.1274\n",
            "Epoch 189 Batch 200 Accuracy 0.0034\n",
            "Epoch 189 Loss 5.003779\n",
            "Time taken for 1 epoch 70.82573008537292 sec\n",
            "\n",
            "Epoch 190 Batch 0 Loss 0.1271\n",
            "Epoch 190 Batch 0 Accuracy 0.0035\n",
            "Epoch 190 Batch 50 Loss 0.1283\n",
            "Epoch 190 Batch 50 Accuracy 0.0036\n",
            "Epoch 190 Batch 100 Loss 0.1274\n",
            "Epoch 190 Batch 100 Accuracy 0.0037\n",
            "Epoch 190 Batch 150 Loss 0.1259\n",
            "Epoch 190 Batch 150 Accuracy 0.0035\n",
            "Epoch 190 Batch 200 Loss 0.1279\n",
            "Epoch 190 Batch 200 Accuracy 0.0034\n",
            "Epoch 190 Loss 5.005699\n",
            "Time taken for 1 epoch 70.34817934036255 sec\n",
            "\n",
            "Epoch 191 Batch 0 Loss 0.1280\n",
            "Epoch 191 Batch 0 Accuracy 0.0033\n",
            "Epoch 191 Batch 50 Loss 0.1278\n",
            "Epoch 191 Batch 50 Accuracy 0.0037\n",
            "Epoch 191 Batch 100 Loss 0.1254\n",
            "Epoch 191 Batch 100 Accuracy 0.0037\n",
            "Epoch 191 Batch 150 Loss 0.1274\n",
            "Epoch 191 Batch 150 Accuracy 0.0032\n",
            "Epoch 191 Batch 200 Loss 0.1254\n",
            "Epoch 191 Batch 200 Accuracy 0.0033\n",
            "Epoch 191 Loss 5.005337\n",
            "Time taken for 1 epoch 70.85013771057129 sec\n",
            "\n",
            "Epoch 192 Batch 0 Loss 0.1269\n",
            "Epoch 192 Batch 0 Accuracy 0.0035\n",
            "Epoch 192 Batch 50 Loss 0.1270\n",
            "Epoch 192 Batch 50 Accuracy 0.0036\n",
            "Epoch 192 Batch 100 Loss 0.1292\n",
            "Epoch 192 Batch 100 Accuracy 0.0034\n",
            "Epoch 192 Batch 150 Loss 0.1274\n",
            "Epoch 192 Batch 150 Accuracy 0.0035\n",
            "Epoch 192 Batch 200 Loss 0.1262\n",
            "Epoch 192 Batch 200 Accuracy 0.0031\n",
            "Epoch 192 Loss 5.002594\n",
            "Time taken for 1 epoch 70.5592098236084 sec\n",
            "\n",
            "Epoch 193 Batch 0 Loss 0.1285\n",
            "Epoch 193 Batch 0 Accuracy 0.0034\n",
            "Epoch 193 Batch 50 Loss 0.1248\n",
            "Epoch 193 Batch 50 Accuracy 0.0035\n",
            "Epoch 193 Batch 100 Loss 0.1261\n",
            "Epoch 193 Batch 100 Accuracy 0.0037\n",
            "Epoch 193 Batch 150 Loss 0.1287\n",
            "Epoch 193 Batch 150 Accuracy 0.0034\n",
            "Epoch 193 Batch 200 Loss 0.1264\n",
            "Epoch 193 Batch 200 Accuracy 0.0039\n",
            "Epoch 193 Loss 5.001960\n",
            "Time taken for 1 epoch 70.57460308074951 sec\n",
            "\n",
            "Epoch 194 Batch 0 Loss 0.1276\n",
            "Epoch 194 Batch 0 Accuracy 0.0035\n",
            "Epoch 194 Batch 50 Loss 0.1270\n",
            "Epoch 194 Batch 50 Accuracy 0.0037\n",
            "Epoch 194 Batch 100 Loss 0.1252\n",
            "Epoch 194 Batch 100 Accuracy 0.0038\n",
            "Epoch 194 Batch 150 Loss 0.1273\n",
            "Epoch 194 Batch 150 Accuracy 0.0036\n",
            "Epoch 194 Batch 200 Loss 0.1288\n",
            "Epoch 194 Batch 200 Accuracy 0.0034\n",
            "Epoch 194 Loss 5.005099\n",
            "Time taken for 1 epoch 70.63781905174255 sec\n",
            "\n",
            "Epoch 195 Batch 0 Loss 0.1277\n",
            "Epoch 195 Batch 0 Accuracy 0.0033\n",
            "Epoch 195 Batch 50 Loss 0.1278\n",
            "Epoch 195 Batch 50 Accuracy 0.0036\n",
            "Epoch 195 Batch 100 Loss 0.1271\n",
            "Epoch 195 Batch 100 Accuracy 0.0035\n",
            "Epoch 195 Batch 150 Loss 0.1274\n",
            "Epoch 195 Batch 150 Accuracy 0.0034\n",
            "Epoch 195 Batch 200 Loss 0.1282\n",
            "Epoch 195 Batch 200 Accuracy 0.0032\n",
            "Epoch 195 Loss 5.003964\n",
            "Time taken for 1 epoch 70.58010077476501 sec\n",
            "\n",
            "Epoch 196 Batch 0 Loss 0.1274\n",
            "Epoch 196 Batch 0 Accuracy 0.0035\n",
            "Epoch 196 Batch 50 Loss 0.1278\n",
            "Epoch 196 Batch 50 Accuracy 0.0036\n",
            "Epoch 196 Batch 100 Loss 0.1260\n",
            "Epoch 196 Batch 100 Accuracy 0.0035\n",
            "Epoch 196 Batch 150 Loss 0.1278\n",
            "Epoch 196 Batch 150 Accuracy 0.0037\n",
            "Epoch 196 Batch 200 Loss 0.1260\n",
            "Epoch 196 Batch 200 Accuracy 0.0036\n",
            "Epoch 196 Loss 5.004014\n",
            "Time taken for 1 epoch 70.97685647010803 sec\n",
            "\n",
            "Epoch 197 Batch 0 Loss 0.1277\n",
            "Epoch 197 Batch 0 Accuracy 0.0033\n",
            "Epoch 197 Batch 50 Loss 0.1304\n",
            "Epoch 197 Batch 50 Accuracy 0.0034\n",
            "Epoch 197 Batch 100 Loss 0.1273\n",
            "Epoch 197 Batch 100 Accuracy 0.0035\n",
            "Epoch 197 Batch 150 Loss 0.1285\n",
            "Epoch 197 Batch 150 Accuracy 0.0032\n",
            "Epoch 197 Batch 200 Loss 0.1280\n",
            "Epoch 197 Batch 200 Accuracy 0.0033\n",
            "Epoch 197 Loss 5.005333\n",
            "Time taken for 1 epoch 70.54991936683655 sec\n",
            "\n",
            "Epoch 198 Batch 0 Loss 0.1293\n",
            "Epoch 198 Batch 0 Accuracy 0.0032\n",
            "Epoch 198 Batch 50 Loss 0.1268\n",
            "Epoch 198 Batch 50 Accuracy 0.0032\n",
            "Epoch 198 Batch 100 Loss 0.1266\n",
            "Epoch 198 Batch 100 Accuracy 0.0037\n",
            "Epoch 198 Batch 150 Loss 0.1276\n",
            "Epoch 198 Batch 150 Accuracy 0.0036\n",
            "Epoch 198 Batch 200 Loss 0.1285\n",
            "Epoch 198 Batch 200 Accuracy 0.0035\n",
            "Epoch 198 Loss 5.002933\n",
            "Time taken for 1 epoch 70.95800590515137 sec\n",
            "\n",
            "Epoch 199 Batch 0 Loss 0.1289\n",
            "Epoch 199 Batch 0 Accuracy 0.0036\n",
            "Epoch 199 Batch 50 Loss 0.1259\n",
            "Epoch 199 Batch 50 Accuracy 0.0034\n",
            "Epoch 199 Batch 100 Loss 0.1273\n",
            "Epoch 199 Batch 100 Accuracy 0.0034\n",
            "Epoch 199 Batch 150 Loss 0.1273\n",
            "Epoch 199 Batch 150 Accuracy 0.0035\n",
            "Epoch 199 Batch 200 Loss 0.1271\n",
            "Epoch 199 Batch 200 Accuracy 0.0035\n",
            "Epoch 199 Loss 5.000958\n",
            "Time taken for 1 epoch 70.31656432151794 sec\n",
            "\n",
            "Epoch 200 Batch 0 Loss 0.1282\n",
            "Epoch 200 Batch 0 Accuracy 0.0034\n",
            "Epoch 200 Batch 50 Loss 0.1271\n",
            "Epoch 200 Batch 50 Accuracy 0.0035\n",
            "Epoch 200 Batch 100 Loss 0.1284\n",
            "Epoch 200 Batch 100 Accuracy 0.0036\n",
            "Epoch 200 Batch 150 Loss 0.1283\n",
            "Epoch 200 Batch 150 Accuracy 0.0036\n",
            "Epoch 200 Batch 200 Loss 0.1254\n",
            "Epoch 200 Batch 200 Accuracy 0.0036\n",
            "Epoch 200 Loss 5.002834\n",
            "Time taken for 1 epoch 69.81754946708679 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}